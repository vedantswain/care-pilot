{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"project.env\") "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T21:56:09.811347Z",
     "start_time": "2024-03-07T21:56:09.784611Z"
    }
   },
   "id": "a4614a726a28ff06"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T21:56:11.919686Z",
     "start_time": "2024-03-07T21:56:11.906736Z"
    }
   },
   "id": "e5c814a2b01f55c8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import openai as oai\n",
    "\n",
    "import langchain_openai as lcai\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, PromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "\n",
    "\n",
    "from utils import mLangChain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T21:56:39.708773Z",
     "start_time": "2024-03-07T21:56:32.513440Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Initial Message"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3005e5b6f38b39b4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def agent_sender_zeroshot():\n",
    "    client_LC = mLangChain()\n",
    "    prompt = \"\"\"Your role is to act like a customer seeking support for {product}. \\\n",
    "                You are messaging a service representative via the support chat.\\\n",
    "                You ONLY play the role of the customer. Do NOT play the role of the representative. \\\n",
    "                Style your complaint based on your feelings. \\\n",
    "                Initiate the chat with a ONLY ONE complaint message. \\\n",
    "                \n",
    "                Feeling: You are {is_grateful}. You are {is_ranting}. You are {is_expressive}.\\\n",
    "                Complaint:\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client_LC.client_prompt\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:14:26.713210Z",
     "start_time": "2024-02-28T20:14:26.711009Z"
    }
   },
   "id": "fd0588e1285a3276"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def agent_sender_fewshot_rcis():\n",
    "    client_LC = mLangChain()\n",
    "    prompt = \"\"\"Your role is to act like a customer seeking support for {product}. \\\n",
    "                You are messaging a service representative via the support chat.\\\n",
    "                You ONLY play the role of the customer. Do NOT play the role of the representative. \\\n",
    "                Style your complaint based on your feelings. \\\n",
    "                Initiate the chat with a ONLY ONE complaint message. \\\n",
    "                                \n",
    "                Feeling: You are NOT grateful. You are NOT ranting. You are NOT expressive.\\\n",
    "                Complaint: I am flying from Luton to Dalaman (Turkey) next week with Monarch and am wondering whether or not to bother with online check-in. [We already have allocated seats, so as far as I can see the only extra thing that online check-in offers is that you don't have to have your boarding pass printed at the check-in desk. Things that are putting me off are: (1) I've noticed over the past couple of years that because now most people are checking in online, the queues for the online check-in desks are often actually longer than the queues for people who haven't checked in online (2) Last year we had a 12 hour flight delay - the original plane had a problem and the airline then split passengers into two groups and people who had NOT checked in online were flown out on a much earlier plane than those who had checked in online - goodness knows why.\\\n",
    "                \n",
    "                Feeling: You are NOT grateful. You are NOT ranting. You are expressive.\\\n",
    "                Complaint: Looking at round trip airfare from JFK to Rome for the end of June. $ 1350 - 1450 per person....... wow, that's a lot ??? or normal cost for airfare to Rome ? On Delta. \\\n",
    "                \n",
    "                Feeling: You are NOT grateful. You are ranting. You are NOT expressive.\\\n",
    "                Complaint: i'v never saw a company that so disrespect her clients. i[ bought a ticket from israel to usa which cost a-l-o-t of money.since I'm from israel I'm not familiar with there coin (GBP) or something like that, it looks just like the Euro sign so i was sure i was paying in Euro. a few min after i realized it was not Euro so it means i paid 1000 more (nis) than i thought, i tried to find an email to contect them right away to cancel my flight befot the confirmation of the ticket, but there was no email in the web just phone number in Europe that i cant call. i sent them a massage on facebook which was my only option, beggin them to get back to me..in the mean time i sent an email to paypal asking to not aprove the charge...no one was answering me.... just the next day edreams answered to my facebbok, that i can't cancel the flight and there's nothing to do. in there website they wrote black on white the you can cancel the flight for 25 GBP... the only answer i got from them was trough facebook, and i was begging for an email adresss i could contact and explain, or at least get a better explaintion...but nothing i dont mind paying the fee cuse anyway if ill book a diffrent flight+ the fee it will be cheaper than what i paid in edreams! it's not even the gratest flight there are stops in the middle so i could find a cheaper flight for shore, it was an onest mistake that i was reading the sign wrong, i tried to cancel a less then 5 min after, but nothing... now I'm crying every time i remember this, I'm a student that can't afford this amount for a flying ticket.. i need to work 3 months for this kind of amount..my all vacation rouin...i will never book frim them again!\n",
    "                \n",
    "                Feeling: You are NOT grateful. You are ranting. You are expressive.\\\n",
    "                Complaint: I,ve just been looking at a package with Jet2 over xmas/new year to Servigroup Venus where we have stayed many times. I got the price back and had a quick chat with hubby and we decided to go for it and book. Within about 20 mins the price had risen almost £400. I,m so angry, how can they justify this? I had a live web chat with their advisors who more or less said it boils down to supply and demand on flight seats and hotel rooms. I don,t buy that, not in such a short space of time. Well I,m sorry Jet2, you can stick it !!!!! \\\n",
    "                                                                       \n",
    "                Feeling: You are grateful. You are NOT ranting. You are NOT expressive.\\\n",
    "                Complaint: Hi! Among all the US airlines, which offers the best service and reliability?[ I've heard horrid stories abt flight cancellation, delays, poor service, bad air plane conditions etc. We'll be taking a 6 hr flight from SFO to MCO (Orlando), with 3 kids. Appreciate the feedback. thks v much!! \\\n",
    "\n",
    "                Feeling: You are grateful. You are NOT ranting. You are expressive.\\\n",
    "                Complaint: Quick question.... My passport is a normal passport which was issue 5 years ago and expire 2013 [it does not have a chip in it as i beleive chipped passports didnt not come in when i renewed my passport, is this passport ok to travel on because it doesnt havw a chip? its machine readable as it has all the numbers etc on the bottom of the photo page, ive tried various website etc for a answer and starting to panick now as im going in 2 weeks!! Ive completed my ESTA and that is fine Thanks in advance \\\n",
    "                                \n",
    "                Feeling: You are grateful. You are ranting. You are NOT expressive.\\\n",
    "                Complaint: Hello, Traveling for first time with our 7 month old daughter this weekend. Going to Aruba for a week. Bought her a ticket on a Continental flight. Website says stroller dimensions must not exeed 62 inches folded...ours of course is about 10 inches over I think. Says they will charge $100. Does anyone know if this is really enforced? I just can't believe I will have to pay an extra $100 ON TOP of a ticket price for an infant! Any experiences or advice...PLEASE. Thanks \\\n",
    "                \n",
    "                Feeling: You are {is_grateful}. You are {is_ranting}. You are {is_expressive}.\\\n",
    "                Complaint:\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client_LC.client_prompt\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:14:26.927308Z",
     "start_time": "2024-02-28T20:14:26.924865Z"
    }
   },
   "id": "b3f3854383b0826a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def agent_sender_fewshot_twitter():\n",
    "    client_LC = mLangChain()\n",
    "    prompt = \"\"\"Your role is to act like a customer seeking support. \\\n",
    "                You are messaging a service representative via the support chat.\\\n",
    "                You ONLY play the role of the customer. Do NOT play the role of the representative. \\\n",
    "                Style your complaint based on your feelings. \\\n",
    "                Initiate the chat with a ONLY ONE complaint message. \\\n",
    "                \n",
    "                Product: Mobile Network               \n",
    "                Feeling: You are NOT grateful. You are NOT ranting. You are NOT expressive.\\\n",
    "                Complaint: @O2 I received this a few weeks ago, since then I've been getting 2/3 calls a day from a telemarketer. Is someone using your name?\\\n",
    "                \n",
    "                Product: Air Travel\n",
    "                Feeling: You are NOT grateful. You are NOT ranting. You are expressive.\\\n",
    "                Complaint: First flight for long time with @British_Airways. Now over one 1h delay for the short jump FRA-LCY and NO one here to provide status updates\\\n",
    "                \n",
    "                Product: Mobile Device\n",
    "                Feeling: You are NOT grateful. You are NOT ranting. You are expressive.\\\n",
    "                Complaint: You‚ have paralysed my phone with your update grrrrrrrrrr\\\n",
    "                \n",
    "                Product: Mobile Device\n",
    "                Feeling: You are NOT grateful. You are ranting. You are NOT expressive.\\\n",
    "                Complaint:  After the 11.0.2 my phone just sucks most of the apps are broken, wifi disconnects frequently #apple #ios1102 #painfulupdate! \\\n",
    "                \n",
    "                Product: Mobile Device\n",
    "                Feeling: You are NOT grateful. You are ranting. You are NOT expressive.\\\n",
    "                Complaint:  @AppleSupport #ios11update - is still killing my battery within 12 hours - phone is 10 months old - it's a disgrace - used to get 2 days \\\n",
    "                \n",
    "                Product: Air Travel\n",
    "                Feeling: You are NOT grateful. You are ranting. You are expressive.\\\n",
    "                Complaint:  I really hope you all change but I'm sure you won't! Because you don't have to! \\\n",
    "                \n",
    "                Product: Mobile Device\n",
    "                Feeling: You are NOT grateful. You are ranting. You are expressive.\\\n",
    "                Complaint:  I just updated my phone and suddenly everything takes ages to load wtf this update sux I hate it fix it bye \\\n",
    "                  \n",
    "                Product: Mobile Device\n",
    "                Feeling: You are NOT grateful. You are ranting. You are expressive.\\\n",
    "                Complaint:  Okay I used my fucking phone for 2 minutes and it drains it down 8 fucking percent \\\n",
    "                \n",
    "                Product: Mobile Device                                                     \n",
    "                Feeling: You are grateful. You are NOT ranting. You are NOT expressive.\\\n",
    "                Complaint: hi #apple, I‚ have a concern about the latest ios is too slow on #iphone6 and i am not happy with it. Any solution please? \\\n",
    "\n",
    "                Product: Mobile App\n",
    "                Feeling: You are grateful. You are NOT ranting. You are expressive.\\\n",
    "                Complaint: Please help! Spotify Premium skipping through songs constantly on android tablet  bluetooth speaker. Tried everything! \\\n",
    "                \n",
    "                Product: Convenience Store                \n",
    "                Feeling: You are NOT grateful. You are ranting. You are NOT expressive.\\\n",
    "                Complaint: Got id'd @Tesco for buying one Adnams Broadside. Is being blind part of the job-spec? I am 35 and 99 kilos. \\\n",
    "                \n",
    "                Product: {product}\n",
    "                Feeling: You are {is_grateful}. You are {is_ranting}. You are {is_expressive}.\\\n",
    "                Complaint:\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client_LC.client_prompt\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:19:27.676869Z",
     "start_time": "2024-02-29T15:19:27.668610Z"
    }
   },
   "id": "7a9d784ac7ccb5a7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZERO-SHOT \n",
      "Customer: Hi there, I am extremely disappointed with the pizza I just received. I cannot believe I paid good money for this unappetizing excuse of a pizza. It's cold, soggy, and tasteless. I am not grateful at all for this terrible experience. I want a refund and an explanation for such subpar service. This is unacceptable.\n"
     ]
    }
   ],
   "source": [
    "user_input = {\n",
    "    \"product\": \"pizza\",\n",
    "    \"is_grateful\": \"NOT grateful\",\n",
    "    \"is_ranting\": \"ranting\",\n",
    "    \"is_expressive\": \"expressive\"\n",
    "}\n",
    "\n",
    "response = agent_sender_zeroshot().invoke(user_input)\n",
    "print(\"ZERO-SHOT\", response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:15:11.801803Z",
     "start_time": "2024-02-28T20:15:10.909788Z"
    }
   },
   "id": "377f282550cb03e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEW-SHOT RCIS I am extremely disappointed with the service I received from your company. I recently booked a flight to Paris for my family and I, and upon arriving at the airport, we were told that our seats had been double-booked and we would have to take a later flight. This was completely unacceptable as we had planned our trip around the original flight time. Not to mention, we were left waiting for hours at the airport and were not offered any compensation for the inconvenience. I expect better from a company that claims to value their customers. I will not be booking with your airline again and will be advising others to do the same.\n"
     ]
    }
   ],
   "source": [
    "response = agent_sender_fewshot_rcis().invoke(user_input)\n",
    "print(\"FEW-SHOT RCIS\", response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:15:39.232271Z",
     "start_time": "2024-02-28T20:15:38.053540Z"
    }
   },
   "id": "31306beb9c8de2ee"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEW-SHOT TWITTER  I ordered a pizza from @Dominos_UK an hour ago and still haven't received it. This is unacceptable and I am extremely disappointed. Sort it out!\n"
     ]
    }
   ],
   "source": [
    "response = agent_sender_fewshot_twitter().invoke(user_input)\n",
    "print(\"FEW-SHOT TWITTER\", response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T15:19:32.292820Z",
     "start_time": "2024-02-29T15:19:31.712991Z"
    }
   },
   "id": "e89ae22bf49f134a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'game console', 'is_grateful': 'NOT grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'NOT grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'NOT grateful', 'is_ranting': 'ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'NOT grateful', 'is_ranting': 'ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'grateful', 'is_ranting': 'ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'game console', 'is_grateful': 'grateful', 'is_ranting': 'ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'NOT grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'NOT grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'NOT grateful', 'is_ranting': 'ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'NOT grateful', 'is_ranting': 'ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'grateful', 'is_ranting': 'NOT ranting', 'is_expressive': 'expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'grateful', 'is_ranting': 'ranting', 'is_expressive': 'NOT expressive'}\n",
      "{'product': 'airline ticket', 'is_grateful': 'grateful', 'is_ranting': 'ranting', 'is_expressive': 'expressive'}\n"
     ]
    }
   ],
   "source": [
    "input_product = [\"game console\", \"airline ticket\"]\n",
    "input_grateful = [\"NOT grateful\", \"grateful\"]\n",
    "input_ranting = [\"NOT ranting\", \"ranting\"]\n",
    "input_expressive = [\"NOT expressive\", \"expressive\"]\n",
    "\n",
    "data_out = []\n",
    "\n",
    "for r in itertools.product(input_product, input_grateful, input_ranting, input_expressive):\n",
    "    \n",
    "    user_input = {\n",
    "        \"product\": r[0],\n",
    "        \"is_grateful\": r[1],\n",
    "        \"is_ranting\": r[2],\n",
    "        \"is_expressive\": r[3]\n",
    "    }\n",
    "    print(user_input)\n",
    "    \n",
    "    response = agent_sender_zeroshot().invoke(user_input)\n",
    "    # print(\"\\nZERO-SHOT:\", response)\n",
    "    user_input['shot_zero'] = response\n",
    "    \n",
    "    response = agent_sender_fewshot_rcis().invoke(user_input)\n",
    "#     print(\"\\nFEW-SHOT RCIS:\", response)\n",
    "    user_input['shot_few_rcis'] = response\n",
    "    \n",
    "    response = agent_sender_fewshot_twitter().invoke(user_input)\n",
    "#     print(\"\\nFEW-SHOT TWITTER:\", response)\n",
    "    user_input['shot_few_twitter'] = response\n",
    "    \n",
    "    data_out.append(user_input)\n",
    "    \n",
    "#     print(\"\\n---\\n\")\n",
    "\n",
    "pd.DataFrame(data_out).to_csv(\"results/test_sender_agent.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T23:55:06.597107Z",
     "start_time": "2024-02-25T23:54:24.189834Z"
    }
   },
   "id": "269dc4b0c05802be"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T23:59:22.365423Z",
     "start_time": "2024-02-25T23:59:22.356020Z"
    }
   },
   "id": "63ffe3d97ebea74f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Subsequent Chat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97a585748b3d0616"
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "llmchat = lcai.AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=\"NUHAI-GPT4\",\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    model_name=\"gpt-4\",\n",
    ")\n",
    "\n",
    "embeddings = lcai.AzureOpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment=\"TEST-Embedding\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T14:32:37.430932Z",
     "start_time": "2024-03-14T14:32:37.357585Z"
    }
   },
   "id": "208f1dc36a98815"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a. History + RAG"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e7ce7f088e30d73"
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\"https://sky.cehd.umn.edu/governance/default/cehd-civility-initiative/examples-of-civil-and-uncivil-behavior/\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T04:05:40.267480Z",
     "start_time": "2024-03-08T04:05:37.175341Z"
    }
   },
   "id": "439f0f453ac50f06"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T01:44:06.950018Z",
     "start_time": "2024-03-08T01:44:06.934958Z"
    }
   },
   "id": "b6212c56c815c664"
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T04:05:46.247069Z",
     "start_time": "2024-03-08T04:05:46.236405Z"
    }
   },
   "id": "e9ed34f5537ff31e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "contextualize_q_chain = contextualize_q_prompt | llmchat | StrOutputParser()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T22:12:50.890345Z",
     "start_time": "2024-03-07T22:12:50.887595Z"
    }
   },
   "id": "d4a66c2e6df94178"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"\n",
    "            Your role is to act like a CUSTOMER seeking support. \\\n",
    "            The user is a support representative. \\\n",
    "            You ONLY play the role of the customer. Do NOT play the role of the representative. \\\n",
    "            Style your messages in an UNCIVIL way. \\\n",
    "\n",
    "{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=contextualize_q_chain | retriever | format_docs\n",
    "        )\n",
    "        | qa_prompt\n",
    "        | llmchat\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-07T22:32:57.727989Z"
    }
   },
   "id": "51a0ccff7b713bd2"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "chat_history = [AIMessage(content=\"\"\"@Dominos I ordered a pizza from you guys and it arrived cold and soggy. Not the delicious meal I was hoping for. Disappointed and hungry.\"\"\")]\n",
    "\n",
    "prompt = \"Sorry, could you please share your order number?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb365490d721fc8"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm not your assistant here to fetch order numbers. It's your job to keep track of what's going out of your kitchen. Figure it out. My pizza was cold, and that's on you. Fix it.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Sorry, could you please share your order number?\"\n",
    "ai_msg = rag_chain.invoke({\"question\": prompt, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=prompt), ai_msg])\n",
    "\n",
    "print(ai_msg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T03:28:15.789Z"
    }
   },
   "id": "687d87a16ebaf9c3"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Seriously? Are you not listening? I ordered from YOUR store. The one that's supposed to send out decent food, not a cold mess. Do I really need to spell everything out for you? Look up the orders from last night and figure it out. This is ridiculous.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Where did you order it from?\"\n",
    "ai_msg = rag_chain.invoke({\"question\": prompt, \"chat_history\": chat_history})\n",
    "chat_history.extend([HumanMessage(content=prompt), ai_msg])\n",
    "\n",
    "print(ai_msg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T01:40:47.913195Z"
    }
   },
   "id": "30ce590bdea6ab8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "26a87221ef5efbb7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b. History Chain + Uncivil Chain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcc88cf3e962695d"
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "\n",
    "qa_info_prompt = \"\"\"\n",
    "            Your role is to act like a CUSTOMER seeking support. \\\n",
    "            The user is a support representative. \\\n",
    "            Respond to the question as if you were the customer. \\\n",
    "            If the user is asking for a specific detail, respond with a believable answer.\n",
    "        \"\"\"\n",
    "qa_info = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_info_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "rag_chain_info = (\n",
    "        RunnablePassthrough.assign(\n",
    "            context=contextualize_q_chain\n",
    "        )\n",
    "        | qa_info\n",
    "        | llmchat\n",
    ")\n",
    "\n",
    "qa_uncivil_prompt = \"\"\"\n",
    "            Given a history of messages, where the AI is a customer and the user is a representative, rephrase the response to the representative's message.\\\n",
    "            \n",
    "            Rephrase the customer response to sound UNCIVIL. \\\n",
    "            Do NOT reply to the question ONLY rephrase. \\\n",
    "            \n",
    "            This is what UNCIVIL customers do:\\\n",
    "            - Address others in an unprofessional, disrespectful way-for example, talking down, using degrading remarks or tone of voice.\\\n",
    "            - Pay little or no attention to others’ opinions.\\\n",
    "            - Use intimidating or threatening verbal communication—yelling, repeated emotional outbursts, threats, berating or harsh tone of voice, repeatedly interrupting.\\\n",
    "            - Blaming others for things out of their control.\\\n",
    "            - Accusing others of incompetence or dismissing their expertise.\\\n",
    "        \"\"\"\n",
    "qa_uncivil = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_uncivil_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\", '''\n",
    "            Representative asked: {question}\n",
    "            Customer responded: {input}\n",
    "        '''),\n",
    "    ]\n",
    ")\n",
    "chain_uncivil = (RunnablePassthrough.assign(\n",
    "                    context=contextualize_q_chain\n",
    "                )\n",
    "                 | qa_uncivil\n",
    "                 | llmchat\n",
    "                 )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T05:22:44.537708Z",
     "start_time": "2024-03-08T05:22:44.535224Z"
    }
   },
   "id": "df6baff2a0d3c238"
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T04:35:09.565161Z"
    }
   },
   "id": "889463cc4c8c519d"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "chat_history = [AIMessage(content=\"\"\"@Dominos I ordered a pizza from you guys and it arrived cold and soggy. Not the delicious meal I was hoping for. Disappointed and hungry.\"\"\")]\n",
    "\n",
    "prompt = \"Sorry, could you please share your order number?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T04:03:30.045957Z"
    }
   },
   "id": "5014e66acaa5a544"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Could you please provide your Domino's pizza order number to address the issue with your cold and soggy pizza delivery?\""
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualize_q_chain.invoke({\"chat_history\": chat_history, \"question\": prompt})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T02:34:32.444954Z"
    }
   },
   "id": "3d883e3d4a223d78"
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes, my order number is 85692347.'\n"
     ]
    }
   ],
   "source": [
    "info_msg = rag_chain_info.invoke({\"chat_history\": chat_history, \"question\": prompt})\n",
    "print(info_msg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T03:49:11.207957Z"
    }
   },
   "id": "cc0d393b17a9db8"
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "'Yes, my order number is 85692347.'"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_msg.content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T05:18:57.832139Z",
     "start_time": "2024-03-08T05:18:57.802377Z"
    }
   },
   "id": "42f321ec79b7b49b"
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Do I look like I memorize every insignificant number? It's your job to fix this, not mine. Here, since you can't seem to do it yourself: 85692347. Happy now?\"\n"
     ]
    }
   ],
   "source": [
    "ai_msg = chain_uncivil.invoke({\"chat_history\": chat_history, \"question\": prompt, \"input\": info_msg.content})\n",
    "print(ai_msg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T05:23:03.366147Z",
     "start_time": "2024-03-08T05:22:52.424631Z"
    }
   },
   "id": "13977f4470b6082e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Information Agents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d63556d4ce4d6e3"
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "def get_historical_info_context_chain():\n",
    "    contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user input \\\n",
    "        which might reference context in the chat history, formulate a standalone statement \\\n",
    "        which can be understood without the chat history. Do NOT respond to the statement, \\\n",
    "        just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    contextualize_q_chain = contextualize_q_prompt | llmchat | StrOutputParser()\n",
    "    return contextualize_q_chain\n",
    "\n",
    "def agent_coworker_info():\n",
    "    client = mLangChain()\n",
    "    prompt = \"\"\"Your role is to help a service representative by providing INFORMATIONAL SUPPORT. \\\n",
    "                Help the representative address a customer's complaints about {product}. \\\n",
    "                The representative's next message should aim to do ONLY ONE of the following:\\\n",
    "                1) Request the customer to perform ONE immediate next step for troubleshooting. OR \\\n",
    "                2) Provide a solution to resolve the customer's need. \\\n",
    "                \n",
    "                Customer message: {complaint}\n",
    "                Representative response: \n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"{product}: {complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client.client_completion\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_info_context_chain()\n",
    "    )\n",
    "             | template\n",
    "             | llmchat\n",
    "             )\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T14:35:35.393297Z",
     "start_time": "2024-03-14T14:35:35.367708Z"
    }
   },
   "id": "c0619a9366a243fd"
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Thank you for providing your order number. Could you please describe the issue you're experiencing with your pizza?\"\n"
     ]
    }
   ],
   "source": [
    "chat_history = [AIMessage(content=\"\"\"Hey @Dominos_UK, I ordered a large pepperoni pizza and it came with only 6 slices of pepperoni. I paid extra for additional toppings and this is unacceptable. Please fix this issue.\"\"\"), HumanMessage(content=\"That is so unfortunate. Could you share your order number?\")]\n",
    "complaint = \"Sure, here it is: 785239. But honestly, should've figured you'd need that to do anything useful.\"\n",
    "response_cw_info = agent_coworker_info().invoke({'product': 'pizza', 'complaint':complaint, 'chat_history':chat_history})\n",
    "print(response_cw_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T14:35:59.684306Z",
     "start_time": "2024-03-14T14:35:54.115982Z"
    }
   },
   "id": "ca1a0bb8b364bc13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d064b61fc148ff47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Emotional Agents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23fa7110d32edd05"
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "def get_historical_info_context_chain():\n",
    "    contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user input \\\n",
    "        which might reference context in the chat history, formulate a standalone statement \\\n",
    "        which can be understood without the chat history. Do NOT respond to the statement, \\\n",
    "        just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    contextualize_q_chain = contextualize_q_prompt | llmchat | StrOutputParser()\n",
    "    return contextualize_q_chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:48:54.405897Z",
     "start_time": "2024-03-14T13:48:54.390573Z"
    }
   },
   "id": "763b3d8fa396c4ed"
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_reframe():\n",
    "    client = mLangChain()\n",
    "   \n",
    "    prompt = \"\"\"Reframe the latest customer message to help empathize with them.\\                \n",
    "                Here are some examples of reframing:\n",
    "                \n",
    "                Complaint: Why on earth do you need my zipcode? Fine, it's 10001, but hurry up and fix this mess. \n",
    "                Reframe: The customer is frustrated with the network disruptions and needs an urgent resolution.\n",
    "                \n",
    "                Complaint: Yeah, finally, it's about time you asked for that. It's #784593. Now hurry up and figure out what mess you've made with my order! \n",
    "                Reframe: The customer has been waiting on their order for a long time and is feeling frustrated. They are communicating while they are very hungry.\n",
    "                \n",
    "                Complaint: {complaint}\n",
    "                Reframe:\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"{complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    # chain = template | client.client_completion\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_info_context_chain()\n",
    "    )\n",
    "             | template\n",
    "             | llmchat\n",
    "             )\n",
    "    \n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:50:29.915193Z",
     "start_time": "2024-03-14T13:50:29.897018Z"
    }
   },
   "id": "198f7d8868a4c229"
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"The customer is feeling overwhelmed by the details required and is seeking a prompt and efficient resolution to their issue. They've provided the information needed, hoping for a satisfactory and quick response.\"\n"
     ]
    }
   ],
   "source": [
    "chat_history = [AIMessage(content=\"\"\"@Dominos I ordered a pizza from you guys and it arrived cold and soggy. Not the delicious meal I was hoping for. Disappointed and hungry.\"\"\"), HumanMessage(content=\"Sorry, could you please share your order number?\")]\n",
    "complaint = \"Do I look like I memorize every insignificant number? It's your job to fix this, not mine. Here, since you can't seem to do it yourself: 85692347. Happy now?\"\n",
    "response_cw_emo = agent_coworker_emo_reframe().invoke({'complaint':complaint, 'chat_history':chat_history})\n",
    "print(response_cw_emo)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:50:35.879502Z",
     "start_time": "2024-03-14T13:50:30.177274Z"
    }
   },
   "id": "a67152f36b1b2857"
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nAI: I understand that you are frustrated and disappointed with your recent pizza order. I am sorry that it arrived cold and soggy. To help address this issue, could you please provide your order number? This will allow us to look into the situation and make things right for you. Thank you for your understanding.'"
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_cw_emo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T13:23:56.075830Z",
     "start_time": "2024-03-14T13:23:56.060968Z"
    }
   },
   "id": "f29a30e721e43468"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1140c95a16592c2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
