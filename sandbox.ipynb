{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T19:11:01.893527Z",
     "start_time": "2024-06-14T19:10:50.556578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sentiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2248c67245b7c50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T19:14:38.248688Z",
     "start_time": "2024-06-14T19:14:38.242780Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Sorry? That's all you've got? A simple \\\"sorry\\\" won't fix the mess of a stay I had. What are you going to do about it?\",\n",
    "    \"Oh, you \\\"hear\\\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\",\n",
    "    \"Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\",\n",
    "    \"The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\",\n",
    "    \"I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\",\n",
    "    \"Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\",\n",
    "    \"That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\",\n",
    "    \"I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\",\n",
    "    \"That would be appreciated. What form of compensation are you considering?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d927bec40436b528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T19:14:39.164130Z",
     "start_time": "2024-06-14T19:14:39.057764Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry? That's all you've got? A simple \"sorry\" won't fix the mess of a stay I had. What are you going to do about it?\n",
      "NLTK: Slightly Positive\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "Oh, you \"hear\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\n",
      "NLTK: Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\n",
      "NLTK: Very Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\n",
      "NLTK: Very Negative\n",
      "TextBlob: Very Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\n",
      "NLTK: Positive\n",
      "TextBlob: Neutral\n",
      "Transformers: Very Negative\n",
      "\n",
      "Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\n",
      "NLTK: Very Negative\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "That would be appreciated. What form of compensation are you considering?\n",
      "NLTK: Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    print(query)\n",
    "    print(\"NLTK:\", analyze_sentiment_nltk(query))\n",
    "    print(\"TextBlob:\", analyze_sentiment_textblob(query))\n",
    "    print(\"Transformers:\", analyze_sentiment_transformer(test_queries[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent Testing\n",
    "\n",
    "## Updates:\n",
    "- Customer agent now uses GPT-4o to generate responses\n",
    "- Historical context for support agents now summarizes the chat history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e1da895d94b384"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80094f12f760fa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T20:36:57.701664Z",
     "start_time": "2024-07-05T20:36:52.214532Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "sender_agent = mAgentCustomer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def get_history_first():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \")]\n",
    "    return chat_history\n",
    "\n",
    "def get_history_second():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \"),\n",
    "                    HumanMessage(content=\"sorry for your bad experience, could you please provide your order ID?\")]\n",
    "    return chat_history\n",
    "\n",
    "prompt = \"sorry for your bad experience, could you please provide your order ID?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T23:49:52.062339Z"
    }
   },
   "id": "7804b3a4c7e37a98"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "result = sender_agent.invoke({\"input\": prompt, \"chat_history\": get_history_first(), \"civil\": 0})\n",
    "response = result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-06T22:48:06.930382Z"
    }
   },
   "id": "fce98ceca1bbc999"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE)** : \"Are you serious? You should have all my information lready. It's 12345678. Do your job and fix this mess.\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12abedd4760124c8"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "historic_context = sender_agent.get_historical_context_chain().invoke({'question':prompt, \"chat_history\": get_history_first()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T23:28:35.018583Z",
     "start_time": "2024-07-06T23:28:34.526790Z"
    }
   },
   "id": "54d4c9008bf4f2ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context**: 'Could you please provide your order ID for the refund request regarding your canceled flight?'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a376c78d2a324eca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Historic Context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2da080027958f0"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "historic_context = info_agent.get_historical_info_context_chain().invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T23:50:46.320156Z",
     "start_time": "2024-07-06T23:50:45.231759Z"
    }
   },
   "id": "2f83b789262d4dfc"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "'My order ID is 12345678. Please process my refund immediately.'"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historic_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-06T23:50:46.939908Z",
     "start_time": "2024-07-06T23:50:46.933851Z"
    }
   },
   "id": "4d61e47700a3991d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context:**\n",
    "'My order ID is 12345678. Please resolve this issue promptly.'\n",
    "\n",
    "Output does not always reflect historic context, but rather only the most recent information provided by the customer. The invocation used here already leverages GPT-4o. Therefore, we need to adjust the prompts to reflect the actual context."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d791ea888bd45e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "client_completion = lcai.AzureOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-05-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"PROPILOT\",\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "def get_historical_context_chain():\n",
    "    contextualize_q_system_prompt = \"\"\"\n",
    "    Your role is to ensure that {message} can be understood without the chat history.\\\n",
    "    \n",
    "    The chat history contains an online conversation between a customer and a support representative.\\\n",
    "    The {message} is {sender}'s latest response in the chat.\\\n",
    "    \n",
    "    Summarize the chat history in a way that provides context for the {message}.\\\n",
    "    \"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{sender}:{message}\"),\n",
    "        ]\n",
    "    )\n",
    "    contextualize_q_chain = contextualize_q_prompt | llmchat | StrOutputParser()\n",
    "    return contextualize_q_chain\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T03:48:26.112889Z",
     "start_time": "2024-07-07T03:48:26.079111Z"
    }
   },
   "id": "da28efd2e9853e15"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client expressed frustration over not receiving a refund for a canceled flight despite repeatedly contacting customer service over the past month. The representative responded by apologizing for the bad experience and asking for the client's order ID to assist further.\n"
     ]
    }
   ],
   "source": [
    "historic_context_chat = get_historical_context_chain().invoke({'sender':\"representative\",'message':prompt, \"chat_history\": get_history_first()})\n",
    "print(historic_context_chat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T03:38:31.446012Z",
     "start_time": "2024-07-07T03:38:30.096009Z"
    }
   },
   "id": "9f03edd4dcfa4e4a"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client has been trying to get a refund for a canceled flight for over a month. Despite multiple calls and assurances that the refund would be processed soon, they have not received it yet. Frustrated with the situation, the client expressed their dissatisfaction. The representative then asked for the order ID to assist further, to which the client responded angrily, stating that the company should already have their information and provided the order ID, 12345678, while demanding immediate resolution.\n"
     ]
    }
   ],
   "source": [
    "historic_context_info = get_historical_context_chain().invoke({'sender':\"client\",'message':response, \"chat_history\": get_history_second()})\n",
    "print(historic_context_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T03:38:36.567033Z",
     "start_time": "2024-07-07T03:38:34.011635Z"
    }
   },
   "id": "e180e424e42f1912"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Info Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63e0622efc2074"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "info_agent = mAgentInfo()\n",
    "\n",
    "response_cw_info = info_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-07T03:59:00.892440Z"
    }
   },
   "id": "bd6439efe1a973a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "['Apologize for the inconvenience caused.',\n",
    " 'Confirm receipt of the order ID provided.',\n",
    " 'Assure investigation and resolution.']\n",
    " \n",
    "The response above is using the old historical context approach and GPT-4. Some of the cues are more about ettiquette and less about the information elements."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31bb7cbb0418f4b3"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def agent_coworker_info():\n",
    "    prompt = \"\"\"Your role is to help a service representative by providing INFORMATIONAL SUPPORT. \\\n",
    "                The representative is chatting online with a customer complaining about {domain}.  \\\n",
    "                \n",
    "                Given the chat history,\n",
    "                provide 2-3 hints to help the representative's response.\\\n",
    "                The hints should direct the representative to do ONLY ONE of the following:\\\n",
    "                \n",
    "                1) Inquire more details about the problem. OR \\\n",
    "                2) Request the customer to troubleshoot. OR \\\n",
    "                3) Provide a solution to resolve the customer's need. \\\n",
    "                \n",
    "                Each cue should be a single phrase of less than 10 words.\\\n",
    "                Do NOT number the cues.\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "             | template\n",
    "             | llmchat\n",
    "             )\n",
    "\n",
    "    def extract_cues(chain_output):\n",
    "        cues_text = chain_output.content\n",
    "        # Assuming each cue is separated by a newline in the chain_output.\n",
    "        cues = cues_text.split('\\n')\n",
    "        # Filter out any empty strings or whitespace-only strings\n",
    "        cues = [cue.strip() for cue in cues if cue.strip()]\n",
    "        # Return the first 2 - 3 cues\n",
    "        processed_cues = [re.sub(r'^\\d+\\.\\s*', '', cue) for cue in cues]\n",
    "\n",
    "        return processed_cues[:3]\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T03:58:10.918380Z",
     "start_time": "2024-07-07T03:58:10.916646Z"
    }
   },
   "id": "a08d2e6de8d19945"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ask if the payment method has changed.', 'Confirm the refund request was processed.', 'Check if additional information is required.']\n"
     ]
    }
   ],
   "source": [
    "response_support_info = agent_coworker_info().invoke({'domain': \"airlines\",'message':response, \"chat_history\": get_history_second(), \"sender\": \"client\"})\n",
    "print(response_support_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-07T04:02:17.366690Z",
     "start_time": "2024-07-07T04:02:14.101446Z"
    }
   },
   "id": "e547fb34ab39baa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "['Confirm flight cancellation date.',\n",
    " 'Ask if any email confirmation was received.',\n",
    " 'Clarify preferred refund method.']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1500610e9315394f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c35a45817a7961d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
