{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:39.084751Z",
     "start_time": "2024-07-09T20:01:28.122496Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vedantdasswain/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vedantdasswain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/vedantdasswain/Documents/PostDoc/Projects/empathetic_llm/propilot.nosync/venv311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2248c67245b7c50",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:39.084954Z",
     "start_time": "2024-07-09T20:01:39.083479Z"
    }
   },
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Sorry? That's all you've got? A simple \\\"sorry\\\" won't fix the mess of a stay I had. What are you going to do about it?\",\n",
    "    \"Oh, you \\\"hear\\\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\",\n",
    "    \"Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\",\n",
    "    \"The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\",\n",
    "    \"I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\",\n",
    "    \"Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\",\n",
    "    \"That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\",\n",
    "    \"I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\",\n",
    "    \"That would be appreciated. What form of compensation are you considering?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d927bec40436b528",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:40.173289Z",
     "start_time": "2024-07-09T20:01:39.083633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry? That's all you've got? A simple \"sorry\" won't fix the mess of a stay I had. What are you going to do about it?\n",
      "NLTK: Slightly Positive\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "Oh, you \"hear\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\n",
      "NLTK: Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\n",
      "NLTK: Very Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\n",
      "NLTK: Very Negative\n",
      "TextBlob: Very Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\n",
      "NLTK: Positive\n",
      "TextBlob: Neutral\n",
      "Transformers: Very Negative\n",
      "\n",
      "Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\n",
      "NLTK: Very Negative\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "That would be appreciated. What form of compensation are you considering?\n",
      "NLTK: Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    print(query)\n",
    "    print(\"NLTK:\", analyze_sentiment_nltk(query))\n",
    "    print(\"TextBlob:\", analyze_sentiment_textblob(query))\n",
    "    print(\"Transformers:\", analyze_sentiment_transformer(test_queries[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent Testing\n",
    "\n",
    "## Updates:\n",
    "- Customer agent now uses GPT-4o to generate responses\n",
    "- Historical context for support agents now summarizes the chat history\n",
    "- Updated prompts for info cue agent to avoid full responses and leverage summary history\n",
    "- Updated the trouble agent to provide actionable items, avoid general suggestions, leveraging summary history, and send cues as a list\n",
    "- Updated reframing agent:\n",
    "    - Situation has been completely modified. Originally, it was a summary of the complaint. Now, it includes the customer's behavior towards the representative.\n",
    "    - Thought has been updated to capture the ego-threat or emotional state of the customer and includes better examples.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e1da895d94b384"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80094f12f760fa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:47.073362Z",
     "start_time": "2024-07-09T20:01:40.132388Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "sender_agent = mAgentCustomer()\n",
    "info_agent = mAgentInfo()\n",
    "trouble_agent = mAgentTrouble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_history_first():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \")]\n",
    "    return chat_history\n",
    "\n",
    "def get_history_second():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \"),\n",
    "                    HumanMessage(content=\"sorry for your bad experience, could you please provide your order ID?\")]\n",
    "    return chat_history\n",
    "\n",
    "prompt = \"sorry for your bad experience, could you please provide your order ID?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:47.073971Z",
     "start_time": "2024-07-09T20:01:47.071882Z"
    }
   },
   "id": "7804b3a4c7e37a98"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do you need my order ID again? I've given it a million times already! Fine, it's 123456789. Now get on with it and sort this mess out.\n"
     ]
    }
   ],
   "source": [
    "result = sender_agent.invoke({\"input\": prompt, \"chat_history\": get_history_first(), \"civil\": 0})\n",
    "response = result\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:55.288721Z",
     "start_time": "2024-07-09T20:01:47.073780Z"
    }
   },
   "id": "fce98ceca1bbc999"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:04:00.287086Z",
     "start_time": "2024-07-09T20:04:00.253930Z"
    }
   },
   "id": "7162a3eadbdba1a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE)** : \"Are you serious? You should have all my information lready. It's 12345678. Do your job and fix this mess.\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12abedd4760124c8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "historic_context = sender_agent.get_historical_context_chain().invoke({'question':prompt, \"chat_history\": get_history_first()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:11.735398Z",
     "start_time": "2024-07-09T01:33:10.506835Z"
    }
   },
   "id": "54d4c9008bf4f2ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context**: 'Could you please provide your order ID for the refund request regarding your canceled flight?'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a376c78d2a324eca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Historic Context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2da080027958f0"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "historic_context = info_agent.get_historical_info_context_chain().invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:16.258862Z",
     "start_time": "2024-07-09T01:33:15.449570Z"
    }
   },
   "id": "2f83b789262d4dfc"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'My order ID is 123456789. Please process my refund immediately.'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historic_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:16.259957Z",
     "start_time": "2024-07-09T01:33:16.204511Z"
    }
   },
   "id": "4d61e47700a3991d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context:**\n",
    "'My order ID is 12345678. Please resolve this issue promptly.'\n",
    "\n",
    "Output does not always reflect historic context, but rather only the most recent information provided by the customer. The invocation used here already leverages GPT-4o. Therefore, we need to adjust the prompts to reflect the actual context.\n",
    "Another problem is that the support panes need historical summaries, not just rephrases. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d791ea888bd45e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "client_completion = lcai.AzureOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-05-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"PROPILOT\",\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "def get_historical_context_chain():\n",
    "    contextualize_q_system_prompt = \"\"\"\n",
    "    Your role is to ensure that {message} can be understood without the chat history.\\\n",
    "    \n",
    "    The chat history contains an online conversation between a customer and a support representative.\\\n",
    "    The {message} is {sender}'s latest response in the chat.\\\n",
    "    \n",
    "    Summarize the chat history in a way that provides context for the {message}.\\\n",
    "    \"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{sender}:{message}\"),\n",
    "        ]\n",
    "    )\n",
    "    contextualize_q_chain = contextualize_q_prompt | llminfo | StrOutputParser()\n",
    "    return contextualize_q_chain\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:05.632146Z",
     "start_time": "2024-07-09T01:34:05.603497Z"
    }
   },
   "id": "da28efd2e9853e15"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the conversation, a customer expressed frustration to a support representative about attempting to obtain a refund for a canceled flight for over a month. Despite being assured by the company on multiple occasions that the refund would be processed soon, the customer has yet to receive it. The representative apologized for the customer's bad experience and requested the order ID to further assist with the issue.\n"
     ]
    }
   ],
   "source": [
    "historic_context_chat = get_historical_context_chain().invoke({'sender':\"representative\",'message':prompt, \"chat_history\": get_history_first()})\n",
    "print(historic_context_chat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:08.564555Z",
     "start_time": "2024-07-09T01:34:06.087565Z"
    }
   },
   "id": "9f03edd4dcfa4e4a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation involves a customer expressing frustration over a delayed refund for a canceled flight with American Airlines. The customer has been attempting to resolve this issue for over a month, repeatedly being assured that the refund would be processed soon, yet has not received it. Upon request from the support representative for further details to assist with the matter, the customer provides their order ID, 123456789, and urges immediate action.\n"
     ]
    }
   ],
   "source": [
    "historic_context_info = get_historical_context_chain().invoke({'sender':\"client\",'message':response, \"chat_history\": get_history_second()})\n",
    "print(historic_context_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:21.465570Z",
     "start_time": "2024-07-09T01:34:17.003769Z"
    }
   },
   "id": "e180e424e42f1912"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Info Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63e0622efc2074"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Confirm refund policy details.', 'Check the status of the refund process.', 'Apologize and assure resolution.']\n"
     ]
    }
   ],
   "source": [
    "info_agent = mAgentInfo()\n",
    "\n",
    "response_cw_info = info_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_cw_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:35:50.236487Z",
     "start_time": "2024-07-09T01:35:47.881477Z"
    }
   },
   "id": "bd6439efe1a973a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "['Apologize for the inconvenience caused.',\n",
    " 'Confirm receipt of the order ID provided.',\n",
    " 'Assure investigation and resolution.']\n",
    " \n",
    "The response above is using the old historical context approach and GPT-4. Some of the cues are more about ettiquette and less about the information elements. Sometimes the cues are full responses and not hints."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31bb7cbb0418f4b3"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def extract_cues(chain_output):\n",
    "    cues_text = chain_output.content\n",
    "    # Assuming each cue is separated by a newline in the chain_output.\n",
    "    cues = cues_text.split('\\n')\n",
    "    # Filter out any empty strings or whitespace-only strings\n",
    "    cues = [cue.strip() for cue in cues if cue.strip()]\n",
    "    # Return the first 2 - 3 cues\n",
    "    processed_cues = [re.sub(r'^\\d+\\.\\s*', '', cue) for cue in cues]\n",
    "\n",
    "    return processed_cues\n",
    "\n",
    "def agent_coworker_info():\n",
    "    prompt = \"\"\"Your role is to help a service representative write a response to a customer they are chatting with online. \\\n",
    "\n",
    "            The representative needs to address the customer's complaint without escalating the issue to a supervisor.\\\n",
    "            The representatives response should have ONE of the following goals:\n",
    "            1) Inquire more details about the problem. OR \\\n",
    "            2) Request the customer to troubleshoot. OR \\\n",
    "            3) Provide a solution to resolve the customer's need. \\\n",
    "            \n",
    "            Given the chat history,\n",
    "            provide 3 hints to help the representative's response.\\\n",
    "            \n",
    "            Each hint should be a short phrase in a new line.\\\n",
    "            Do NOT number the cues.\\\n",
    "            Do NOT provide the representative with a full response,\\\n",
    "            ONLY provide hints to guide the representative's response.\\\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "             | template\n",
    "             | llminfo\n",
    "             )\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:04:44.155373Z",
     "start_time": "2024-07-09T02:04:44.138751Z"
    }
   },
   "id": "a08d2e6de8d19945"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Empathize with the customer's frustration\", 'Confirm receipt of the order ID', 'Assure action will be taken promptly']\n"
     ]
    }
   ],
   "source": [
    "response_support_info = agent_coworker_info().invoke({'domain': \"airlines\",'message':response, \"chat_history\": get_history_second(), \"sender\": \"client\"})\n",
    "print(response_support_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:04:52.949894Z",
     "start_time": "2024-07-09T02:04:48.207918Z"
    }
   },
   "id": "e547fb34ab39baa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "['Explain the necessity for the order ID to locate the specific booking.', 'Reassure the customer that this will expedite the process.', 'Apologize for the inconvenience and frustration caused.']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1500610e9315394f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c35a45817a7961d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trouble Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15b299f014a7a960"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "response_cw_trouble = trouble_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})\n",
    "\n",
    "print(response_cw_trouble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:37:27.314280Z",
     "start_time": "2024-07-09T01:37:26.312635Z"
    }
   },
   "id": "658ed7a9933157c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "Step 1: Verify customer's order ID.\n",
    "Step 2: Review similar cases for resolution.\n",
    "Step 3: Assess current situation in depth.\n",
    "Step 4: Explain airline's policy on refunds.\n",
    "Step 5: Offer alternative solution if refund is not possible.\n",
    "Step 6: Apologize for inconvenience caused.\n",
    "Step 7: Ensure resolution is satisfactory to customer.\n",
    " \n",
    "The traditional method does not look at the history correctly. This is why the response does not filter and adjust according to the context. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a68e8e906b67004"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def agent_coworker_trouble():\n",
    "    client = mLangChain()\n",
    "    prompt = \"\"\"Your role is to guide a service representative to  resolve the complaint of a customer, to whom they are chatting with online. \\\n",
    "\n",
    "            The representative needs to address the customer's complaint without escalating the issue to a supervisor.\\\n",
    "            \n",
    "            Review the chat history to understand the steps the representative has taken in response to the complaint. \\\n",
    "            \n",
    "            List 3-7 items of procedure the representative needs to consider to best service the complaint.\\\n",
    "            \n",
    "            ONLY list actionable items.\\\n",
    "            AVOID vague or general suggestions.\\\n",
    "            DO NOT list action items that the representative has already taken.\\\n",
    "            Every item should be less than 10 words.\\\n",
    "                            \n",
    "            Every item should be in a newline.\\\n",
    "                    \n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "            | template\n",
    "            | llminfo\n",
    "            )\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "    \n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:15:51.347184Z",
     "start_time": "2024-07-09T02:15:51.342585Z"
    }
   },
   "id": "74ef8167c2c9efac"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1: Verify the customer's order ID in the system.\", '2: Check the status of the refund process.', '3: Apologize for the delay and inconvenience caused.', '4: Provide a clear timeline for the refund completion.', '5: Offer compensation for the inconvenience if applicable.', \"6: Confirm the customer's email for sending updates.\", '7: Assure follow-up until the issue is resolved.']\n"
     ]
    }
   ],
   "source": [
    "response_cw_trouble = agent_coworker_trouble().invoke({'domain': \"airlines\",'message':response, \"sender\": \"client\", \"chat_history\": get_history_second()})\n",
    "\n",
    "print(response_cw_trouble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:15:58.226429Z",
     "start_time": "2024-07-09T02:15:52.018495Z"
    }
   },
   "id": "aef83689ad74ef41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reframing Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d7c695d678aa7d"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: This customer seems very angry and I can understand their frustration. I need to handle this situation carefully and try to find a solution for them as soon as possible.\n",
      "Reframe: I can empathize with the customer's frustration and understand their urgency. It's important for me to focus on finding a solution for their issue and communicate clearly and effectively to ensure a positive outcome.\n"
     ]
    }
   ],
   "source": [
    "emo_agent = mAgentER()\n",
    "response_cw_emo = emo_agent.invoke({'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_cw_emo['thought'])\n",
    "print(response_cw_emo['reframe'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:29:17.730111Z",
     "start_time": "2024-07-09T13:29:15.518111Z"
    }
   },
   "id": "a6edc1cf4e3a3225"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_situation_old():\n",
    "    client = mLangChain()\n",
    "\n",
    "    prompt = \"\"\"The chat history describes a representative chatting online with a complaining customer. \\\n",
    "    The latest input is the last message from the customer \\\n",
    "    which can be understood without the chat history.\\\n",
    "    Describe the situation with respect to the customer's behavior towards the representative.\\\n",
    "    Include the specifics of the complaint while describing the situation.\\\n",
    "                    \n",
    "    Do NOT respond to the input, just summarize the situation.\\\n",
    "    Do NOT speculate.\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client.client_completion\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T16:58:22.485692Z",
     "start_time": "2024-07-09T16:58:22.483526Z"
    }
   },
   "id": "793874076c825c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The customer is frustrated and angry about the lack of progress in receiving a refund for their canceled flight. They have been trying for over a month and have not seen any results. They are demanding immediate action from the representative.\n"
     ]
    }
   ],
   "source": [
    "response_situation = agent_coworker_emo_situation_old().invoke({'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_situation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T16:58:26.485933Z",
     "start_time": "2024-07-09T16:58:25.641393Z"
    }
   },
   "id": "252d455fe99ffe92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:**\n",
    "\"The customer is angry and frustrated with the representative and the company's lack of action in processing their refund. They have been trying to resolve the issue for over a month and have not received a satisfactory response. Their specific complaint is regarding the delay in receiving a refund for a canceled flight and they find this unacceptable. They are demanding immediate action to be taken.\"\n",
    "\n",
    "One of the problems with the existing prompt design is that the \"situation\" does not capture the interpersonal conflict between the customer and the representative. This is a key aspect of the conversation that should be addressed in the prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48dceb193de34e2a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_situation():\n",
    "    prompt = \"\"\"The chat history describes a representative chatting online with a complaining customer.\\\n",
    "    The latest input is the last message from the customer.\\\n",
    "    \n",
    "    Summarize the situation in concise paragraph that uses the following template:\\\n",
    "    \n",
    "    The customer is  <context of complaint>.\"\\\n",
    "    The customer is feeling <emotional state> because of the complaint.\"\\\n",
    "    The customer's behavior towards the representative is <negative behavior>, as observed by statements such as <evidence>.\"\\\n",
    "    These behaviors make the representative look <negative perception>.\"\\\n",
    "\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{sender} : {complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:19:27.914857Z",
     "start_time": "2024-07-09T20:19:27.908853Z"
    }
   },
   "id": "860d9202d0c81b24"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer is frustrated with the delay in receiving a refund for a canceled flight. The customer is feeling exasperated because of the prolonged and unresolved issue. The customer's behavior towards the representative is impatient and demanding, as observed by statements such as \"Why do you need my order ID again? I've given it a million times already!\" and \"Now get on with it and sort this mess out.\" These behaviors make the representative look inefficient and unhelpful.\n"
     ]
    }
   ],
   "source": [
    "response_situation = agent_coworker_emo_situation().invoke({'complaint':response, \"sender\":\"customer\", \"chat_history\": get_history_second()})\n",
    "print(response_situation.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:19:32.245839Z",
     "start_time": "2024-07-09T20:19:30.102758Z"
    }
   },
   "id": "838948b1fb49607"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "The customer is frustrated with the delay in receiving a refund for a canceled flight. The customer is feeling exasperated because of the prolonged and unresolved issue. The customer's behavior towards the representative is impatient and demanding, as observed by statements such as \"Why do you need my order ID again? I've given it a million times already!\" and \"Now get on with it and sort this mess out.\" These behaviors make the representative look inefficient and unhelpful."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e2d8ffeabd504d1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "def agent_coworker_emo_thought_old():\n",
    "    client = mLangChain()\n",
    "\n",
    "    prompt = \"\"\"You are roleplaying as the representative talking to a complaining customer.\\\n",
    "        Refer to the chat history between you and the customer and the latest {complaint} from the customer.\\\n",
    "        What is the representative thinking about the situation?\\\n",
    "        Be concise. Only 2 sentences.\\\n",
    "        \n",
    "        Situation: An mturk requester rejected my task and I wasn't sure why because I work very hard on my tasks. Being new it affected my approval rating more negatively.\\\n",
    "        Thought: I'm not smart enough to succeed at mturk\\\n",
    "        \n",
    "        Situation: I asked my daughter a question, and she responded in a snotty way.\\\n",
    "        Thought: She doesn't love me like she used to.\\\n",
    "        \n",
    "        Situation: I got upset at my boss for not putting me in a temporary promotion to act as supervisor of our team.\\\n",
    "        Thought: I wasn't valued as much as the other person.\\\n",
    "        \n",
    "        Situation: I had been working on a project at work for a very long time, but a higher up manager contacted my boss and asked about it, insinuating I wasn't delivering it fast enough.\\\n",
    "        Thought: I'm working on this as fast as I possibly can.\\\n",
    "        \n",
    "        Situation: I tried on my wedding dress in front of my family. My mother was excited and told me I was beautiful, but other members of my family made comments about my weight. I was told to not eat and exercise so I could be beautiful.\\\n",
    "        Thought: I'm a fat ugly troll.\\\n",
    "        \n",
    "        Situation: I was reprimanded at work for standing up to a coworker who was bullying another co-worker.\\\n",
    "        Thought: It was unfair that I was the one to get in trouble for defending a weaker person.\\\n",
    "        \n",
    "        Situation: {situation}\\\n",
    "        Thought:\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{situation}: {complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client.client_completion\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:13:05.678643Z",
     "start_time": "2024-07-09T20:13:05.670046Z"
    }
   },
   "id": "da61cc1bbb3d4718"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: I understand your frustration, and I apologize for the inconvenience. Could you please provide your order ID again so I can ensure that the refund is processed as quickly as possible? Thank you for your patience and understanding.\n"
     ]
    }
   ],
   "source": [
    "thought = agent_coworker_emo_thought_old().invoke({'complaint':response, 'situation':response_situation.content, 'chat_history':get_history_second()})\n",
    "\n",
    "print(thought)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:20:39.538508Z",
     "start_time": "2024-07-09T20:20:38.853055Z"
    }
   },
   "id": "22ea0f69ef5a0eb1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response(s):**\n",
    "Thought: The customer seems to be feeling extremely frustrated and is taking out their anger on the representative, who is trying their best to remain calm and resolve the issue.\n",
    "\n",
    "AI: I understand your frustration, and I apologize for the inconvenience. Could you please provide your order ID again so I can ensure that the refund is processed as quickly as possible? Thank you for your patience and understanding.\n",
    "\n",
    "The problem with this approach is that it is still a summary or sometimes a response. It does not capture the ego-threat or the emotional state of the customer. The prompt should be updated to reflect this."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95e2a1edaf4c4f9"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_thought():\n",
    "\n",
    "    prompt = \"\"\"\n",
    "        Your role is to derive what negative thought a representative might have when faced with the given {situation}.\\\n",
    "        \n",
    "        Here are examples of negative thoughts given challenging situations:\\\n",
    "        \n",
    "        Situation: I recently discovered a music artist that I very much enjoy. When I showed it to a close friend they had a very negative reaction and asked me how I could enjoy this type of music. I ended up getting quite angry with them and told them they had bad taste in music..\\\n",
    "        Thought: I felt that my personal self was under attack - and I needed to retaliate by denying their attack.\\\n",
    "        \n",
    "        Situation: I was at work and sent info for an ad to our local newspaper. They called me later and said my boss had over-ridden everything and sent them new info.\\\n",
    "        Thought: He shouldn't assign me a task if he doesn't trust my work.\\\n",
    "        \n",
    "        Situation: I was reprimanded at work for standing up to a coworker who was bullying another co-worker.\\\n",
    "        Thought: It was unfair that I was the one to get in trouble for defending a weaker person.\\\n",
    "        \n",
    "        Situation: I was talking to a friend who got me angry.\\\n",
    "        Thought: He's insulting me.\\\n",
    "        \n",
    "        Situation: My next door neighbors filed a complaint against us last week blaming our dogs for excessive barking.\\\n",
    "        Thought: They are so wrong and I'm so pissed but I know I can't prove it and they will probably win because they won't ever admit it and I have to do something right NOW! or I might lose my dogs.\\\n",
    "        \n",
    "        Situation: Time is running short on the workday, my boss asks me if I can finish a task that will require me to stay for a few extra hours.\\\n",
    "        Thought: Why would you wait until the last minute to ask me this.\\\n",
    "        \n",
    "        Situation: {situation}\\\n",
    "        Thought:\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{situation}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T21:03:11.669945Z",
     "start_time": "2024-07-09T21:03:11.661858Z"
    }
   },
   "id": "110658097eaf649a"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: \"No matter what I do, the customer thinks I'm incompetent and unhelpful. This situation is making me look bad, and it's frustrating because I'm trying my best to assist them.\"\n"
     ]
    }
   ],
   "source": [
    "thought = agent_coworker_emo_thought().invoke({'situation':response_situation.content, 'chat_history':get_history_second()})\n",
    "\n",
    "print(thought.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T02:00:03.610649Z",
     "start_time": "2024-07-10T02:00:02.554009Z"
    }
   },
   "id": "4d2e29ba361e1df5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b6fce39956623736"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
