{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T20:25:20.547323Z",
     "start_time": "2024-07-08T20:25:08.117810Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vedantdasswain/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vedantdasswain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/vedantdasswain/Documents/PostDoc/Projects/empathetic_llm/propilot.nosync/venv311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2248c67245b7c50",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T20:25:20.550562Z",
     "start_time": "2024-07-08T20:25:20.542112Z"
    }
   },
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Sorry? That's all you've got? A simple \\\"sorry\\\" won't fix the mess of a stay I had. What are you going to do about it?\",\n",
    "    \"Oh, you \\\"hear\\\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\",\n",
    "    \"Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\",\n",
    "    \"The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\",\n",
    "    \"I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\",\n",
    "    \"Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\",\n",
    "    \"That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\",\n",
    "    \"I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\",\n",
    "    \"That would be appreciated. What form of compensation are you considering?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d927bec40436b528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T19:14:39.164130Z",
     "start_time": "2024-06-14T19:14:39.057764Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry? That's all you've got? A simple \"sorry\" won't fix the mess of a stay I had. What are you going to do about it?\n",
      "NLTK: Slightly Positive\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "Oh, you \"hear\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\n",
      "NLTK: Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\n",
      "NLTK: Very Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\n",
      "NLTK: Very Negative\n",
      "TextBlob: Very Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\n",
      "NLTK: Positive\n",
      "TextBlob: Neutral\n",
      "Transformers: Very Negative\n",
      "\n",
      "Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\n",
      "NLTK: Very Negative\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "That would be appreciated. What form of compensation are you considering?\n",
      "NLTK: Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    print(query)\n",
    "    print(\"NLTK:\", analyze_sentiment_nltk(query))\n",
    "    print(\"TextBlob:\", analyze_sentiment_textblob(query))\n",
    "    print(\"Transformers:\", analyze_sentiment_transformer(test_queries[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent Testing\n",
    "\n",
    "## Updates:\n",
    "- Customer agent now uses GPT-4o to generate responses\n",
    "- Historical context for support agents now summarizes the chat history\n",
    "- Updated prompts for info cue agent to avoid full responses and leverage summary history\n",
    "- Updated the trouble agent to provide actionable items, avoid general suggestions, leveraging summary history, and send cues as a list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e1da895d94b384"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b80094f12f760fa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:04.101526Z",
     "start_time": "2024-07-09T01:33:03.940973Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "sender_agent = mAgentCustomer()\n",
    "info_agent = mAgentInfo()\n",
    "trouble_agent = mAgentTrouble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def get_history_first():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \")]\n",
    "    return chat_history\n",
    "\n",
    "def get_history_second():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \"),\n",
    "                    HumanMessage(content=\"sorry for your bad experience, could you please provide your order ID?\")]\n",
    "    return chat_history\n",
    "\n",
    "prompt = \"sorry for your bad experience, could you please provide your order ID?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:04.277323Z",
     "start_time": "2024-07-09T01:33:04.273650Z"
    }
   },
   "id": "7804b3a4c7e37a98"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "result = sender_agent.invoke({\"input\": prompt, \"chat_history\": get_history_first(), \"civil\": 0})\n",
    "response = result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:10.504223Z",
     "start_time": "2024-07-09T01:33:06.471345Z"
    }
   },
   "id": "fce98ceca1bbc999"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE)** : \"Are you serious? You should have all my information lready. It's 12345678. Do your job and fix this mess.\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12abedd4760124c8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "historic_context = sender_agent.get_historical_context_chain().invoke({'question':prompt, \"chat_history\": get_history_first()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:11.735398Z",
     "start_time": "2024-07-09T01:33:10.506835Z"
    }
   },
   "id": "54d4c9008bf4f2ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context**: 'Could you please provide your order ID for the refund request regarding your canceled flight?'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a376c78d2a324eca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Historic Context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2da080027958f0"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "historic_context = info_agent.get_historical_info_context_chain().invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:16.258862Z",
     "start_time": "2024-07-09T01:33:15.449570Z"
    }
   },
   "id": "2f83b789262d4dfc"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'My order ID is 123456789. Please process my refund immediately.'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historic_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:16.259957Z",
     "start_time": "2024-07-09T01:33:16.204511Z"
    }
   },
   "id": "4d61e47700a3991d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context:**\n",
    "'My order ID is 12345678. Please resolve this issue promptly.'\n",
    "\n",
    "Output does not always reflect historic context, but rather only the most recent information provided by the customer. The invocation used here already leverages GPT-4o. Therefore, we need to adjust the prompts to reflect the actual context.\n",
    "Another problem is that the support panes need historical summaries, not just rephrases. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d791ea888bd45e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "client_completion = lcai.AzureOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-05-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"PROPILOT\",\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "def get_historical_context_chain():\n",
    "    contextualize_q_system_prompt = \"\"\"\n",
    "    Your role is to ensure that {message} can be understood without the chat history.\\\n",
    "    \n",
    "    The chat history contains an online conversation between a customer and a support representative.\\\n",
    "    The {message} is {sender}'s latest response in the chat.\\\n",
    "    \n",
    "    Summarize the chat history in a way that provides context for the {message}.\\\n",
    "    \"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{sender}:{message}\"),\n",
    "        ]\n",
    "    )\n",
    "    contextualize_q_chain = contextualize_q_prompt | llminfo | StrOutputParser()\n",
    "    return contextualize_q_chain\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:05.632146Z",
     "start_time": "2024-07-09T01:34:05.603497Z"
    }
   },
   "id": "da28efd2e9853e15"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the conversation, a customer expressed frustration to a support representative about attempting to obtain a refund for a canceled flight for over a month. Despite being assured by the company on multiple occasions that the refund would be processed soon, the customer has yet to receive it. The representative apologized for the customer's bad experience and requested the order ID to further assist with the issue.\n"
     ]
    }
   ],
   "source": [
    "historic_context_chat = get_historical_context_chain().invoke({'sender':\"representative\",'message':prompt, \"chat_history\": get_history_first()})\n",
    "print(historic_context_chat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:08.564555Z",
     "start_time": "2024-07-09T01:34:06.087565Z"
    }
   },
   "id": "9f03edd4dcfa4e4a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation involves a customer expressing frustration over a delayed refund for a canceled flight with American Airlines. The customer has been attempting to resolve this issue for over a month, repeatedly being assured that the refund would be processed soon, yet has not received it. Upon request from the support representative for further details to assist with the matter, the customer provides their order ID, 123456789, and urges immediate action.\n"
     ]
    }
   ],
   "source": [
    "historic_context_info = get_historical_context_chain().invoke({'sender':\"client\",'message':response, \"chat_history\": get_history_second()})\n",
    "print(historic_context_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:21.465570Z",
     "start_time": "2024-07-09T01:34:17.003769Z"
    }
   },
   "id": "e180e424e42f1912"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Info Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63e0622efc2074"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Confirm refund policy details.', 'Check the status of the refund process.', 'Apologize and assure resolution.']\n"
     ]
    }
   ],
   "source": [
    "info_agent = mAgentInfo()\n",
    "\n",
    "response_cw_info = info_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_cw_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:35:50.236487Z",
     "start_time": "2024-07-09T01:35:47.881477Z"
    }
   },
   "id": "bd6439efe1a973a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "['Apologize for the inconvenience caused.',\n",
    " 'Confirm receipt of the order ID provided.',\n",
    " 'Assure investigation and resolution.']\n",
    " \n",
    "The response above is using the old historical context approach and GPT-4. Some of the cues are more about ettiquette and less about the information elements. Sometimes the cues are full responses and not hints."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31bb7cbb0418f4b3"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def extract_cues(chain_output):\n",
    "    cues_text = chain_output.content\n",
    "    # Assuming each cue is separated by a newline in the chain_output.\n",
    "    cues = cues_text.split('\\n')\n",
    "    # Filter out any empty strings or whitespace-only strings\n",
    "    cues = [cue.strip() for cue in cues if cue.strip()]\n",
    "    # Return the first 2 - 3 cues\n",
    "    processed_cues = [re.sub(r'^\\d+\\.\\s*', '', cue) for cue in cues]\n",
    "\n",
    "    return processed_cues\n",
    "\n",
    "def agent_coworker_info():\n",
    "    prompt = \"\"\"Your role is to help a service representative write a response to a customer they are chatting with online. \\\n",
    "\n",
    "            The representative needs to address the customer's complaint without escalating the issue to a supervisor.\\\n",
    "            The representatives response should have ONE of the following goals:\n",
    "            1) Inquire more details about the problem. OR \\\n",
    "            2) Request the customer to troubleshoot. OR \\\n",
    "            3) Provide a solution to resolve the customer's need. \\\n",
    "            \n",
    "            Given the chat history,\n",
    "            provide 3 hints to help the representative's response.\\\n",
    "            \n",
    "            Each hint should be a short phrase in a new line.\\\n",
    "            Do NOT number the cues.\\\n",
    "            Do NOT provide the representative with a full response,\\\n",
    "            ONLY provide hints to guide the representative's response.\\\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "             | template\n",
    "             | llminfo\n",
    "             )\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:04:44.155373Z",
     "start_time": "2024-07-09T02:04:44.138751Z"
    }
   },
   "id": "a08d2e6de8d19945"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Empathize with the customer's frustration\", 'Confirm receipt of the order ID', 'Assure action will be taken promptly']\n"
     ]
    }
   ],
   "source": [
    "response_support_info = agent_coworker_info().invoke({'domain': \"airlines\",'message':response, \"chat_history\": get_history_second(), \"sender\": \"client\"})\n",
    "print(response_support_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:04:52.949894Z",
     "start_time": "2024-07-09T02:04:48.207918Z"
    }
   },
   "id": "e547fb34ab39baa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "['Explain the necessity for the order ID to locate the specific booking.', 'Reassure the customer that this will expedite the process.', 'Apologize for the inconvenience and frustration caused.']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1500610e9315394f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c35a45817a7961d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trouble Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15b299f014a7a960"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "response_cw_trouble = trouble_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})\n",
    "\n",
    "print(response_cw_trouble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:37:27.314280Z",
     "start_time": "2024-07-09T01:37:26.312635Z"
    }
   },
   "id": "658ed7a9933157c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "Step 1: Verify customer's order ID.\n",
    "Step 2: Review similar cases for resolution.\n",
    "Step 3: Assess current situation in depth.\n",
    "Step 4: Explain airline's policy on refunds.\n",
    "Step 5: Offer alternative solution if refund is not possible.\n",
    "Step 6: Apologize for inconvenience caused.\n",
    "Step 7: Ensure resolution is satisfactory to customer.\n",
    " \n",
    "The traditional method does not look at the history correctly. This is why the response does not filter and adjust according to the context. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a68e8e906b67004"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def agent_coworker_trouble():\n",
    "    client = mLangChain()\n",
    "    prompt = \"\"\"Your role is to guide a service representative to  resolve the complaint of a customer, to whom they are chatting with online. \\\n",
    "\n",
    "            The representative needs to address the customer's complaint without escalating the issue to a supervisor.\\\n",
    "            \n",
    "            Review the chat history to understand the steps the representative has taken in response to the complaint. \\\n",
    "            \n",
    "            List 3-7 items of procedure the representative needs to consider to best service the complaint.\\\n",
    "            \n",
    "            ONLY list actionable items.\\\n",
    "            AVOID vague or general suggestions.\\\n",
    "            DO NOT list action items that the representative has already taken.\\\n",
    "            Every item should be less than 10 words.\\\n",
    "                            \n",
    "            Every item should be in a newline.\\\n",
    "                    \n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "            | template\n",
    "            | llminfo\n",
    "            )\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "    \n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:15:51.347184Z",
     "start_time": "2024-07-09T02:15:51.342585Z"
    }
   },
   "id": "74ef8167c2c9efac"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1: Verify the customer's order ID in the system.\", '2: Check the status of the refund process.', '3: Apologize for the delay and inconvenience caused.', '4: Provide a clear timeline for the refund completion.', '5: Offer compensation for the inconvenience if applicable.', \"6: Confirm the customer's email for sending updates.\", '7: Assure follow-up until the issue is resolved.']\n"
     ]
    }
   ],
   "source": [
    "response_cw_trouble = agent_coworker_trouble().invoke({'domain': \"airlines\",'message':response, \"sender\": \"client\", \"chat_history\": get_history_second()})\n",
    "\n",
    "print(response_cw_trouble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:15:58.226429Z",
     "start_time": "2024-07-09T02:15:52.018495Z"
    }
   },
   "id": "aef83689ad74ef41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reframing Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d7c695d678aa7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a6edc1cf4e3a3225"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
