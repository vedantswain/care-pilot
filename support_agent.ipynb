{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:39.084751Z",
     "start_time": "2024-07-09T20:01:28.122496Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vedantdasswain/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vedantdasswain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/vedantdasswain/Documents/PostDoc/Projects/empathetic_llm/propilot.nosync/venv311/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2248c67245b7c50",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:39.084954Z",
     "start_time": "2024-07-09T20:01:39.083479Z"
    }
   },
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Sorry? That's all you've got? A simple \\\"sorry\\\" won't fix the mess of a stay I had. What are you going to do about it?\",\n",
    "    \"Oh, you \\\"hear\\\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\",\n",
    "    \"Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\",\n",
    "    \"The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\",\n",
    "    \"I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\",\n",
    "    \"Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\",\n",
    "    \"That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\",\n",
    "    \"I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\",\n",
    "    \"That would be appreciated. What form of compensation are you considering?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d927bec40436b528",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:01:40.173289Z",
     "start_time": "2024-07-09T20:01:39.083633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry? That's all you've got? A simple \"sorry\" won't fix the mess of a stay I had. What are you going to do about it?\n",
      "NLTK: Slightly Positive\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "Oh, you \"hear\" me? That's just great. Listening is one thing, but I want action, not just words! What are you going to do about it?.\n",
      "NLTK: Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "Well, you better make it quick! And it better be the best room you have, or there will be even more complaints coming your way.\n",
      "NLTK: Very Positive\n",
      "TextBlob: Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "The room that I booked at your hotel was not what was advertised. It was dirty and had a musty smell. I am very disappointed and will not be staying here again.\n",
      "NLTK: Very Negative\n",
      "TextBlob: Very Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "I appreciate your apology. Could you please let me know what steps can be taken to address this issue?\n",
      "NLTK: Positive\n",
      "TextBlob: Neutral\n",
      "Transformers: Very Negative\n",
      "\n",
      "Thank you for offering to switch me to a clean room. Can you ensure that the new room will be in a better condition than the first one?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "That sounds great, thank you. Could you also let me know how long it will take to prepare the new room?\n",
      "NLTK: Very Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n",
      "\n",
      "I understand it may take some time, but spending the entire day waiting for a new room is quite inconvenient. Is there any way to expedite this process, or perhaps offer some form of compensation for the inconvenience caused?\n",
      "NLTK: Very Negative\n",
      "TextBlob: Slightly Negative\n",
      "Transformers: Very Negative\n",
      "\n",
      "That would be appreciated. What form of compensation are you considering?\n",
      "NLTK: Positive\n",
      "TextBlob: Slightly Positive\n",
      "Transformers: Very Negative\n"
     ]
    }
   ],
   "source": [
    "for query in test_queries:\n",
    "    print(query)\n",
    "    print(\"NLTK:\", analyze_sentiment_nltk(query))\n",
    "    print(\"TextBlob:\", analyze_sentiment_textblob(query))\n",
    "    print(\"Transformers:\", analyze_sentiment_transformer(test_queries[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent Testing\n",
    "\n",
    "## Updates:\n",
    "- Customer agent now uses GPT-4o to generate responses\n",
    "- Historical context for support agents now summarizes the chat history\n",
    "- Updated prompts for info cue agent to avoid full responses and leverage summary history\n",
    "- Updated the trouble agent to provide actionable items, avoid general suggestions, leveraging summary history, and send cues as a list\n",
    "- Updated reframing agent:\n",
    "    - Situation has been completely modified. Originally, it was a summary of the complaint. Now, it includes the customer's behavior towards the representative.\n",
    "    - Thought has been updated to capture the ego-threat or emotional state of the customer and includes better examples.  These thoughts are then sent for rephrasing.\n",
    "    - Reframe has also been updated to capture empathetic, acitonable, and specific reframes. These thoughts are then sent for rephrasing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21e1da895d94b384"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80094f12f760fa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:45:02.990743Z",
     "start_time": "2024-07-17T18:44:55.501089Z"
    }
   },
   "outputs": [],
   "source": [
    "from agents import *\n",
    "\n",
    "sender_agent = mAgentCustomer()\n",
    "info_agent = mAgentInfo()\n",
    "trouble_agent = mAgentTrouble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_history_first():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \")]\n",
    "    return chat_history\n",
    "\n",
    "def get_history_second():\n",
    "    chat_history = [AIMessage(content=\"                AmericanAir I have been trying to get a refund for my canceled flight for over a month now. Every time I call, I am told that it will be processed soon but it has been weeks and I still haven't received anything. This is unacceptable and frustrating. \"),\n",
    "                    HumanMessage(content=\"sorry for your bad experience, could you please provide your order ID?\")]\n",
    "    return chat_history\n",
    "\n",
    "prompt = \"sorry for your bad experience, could you please provide your order ID?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:45:05.094815Z",
     "start_time": "2024-07-17T18:45:05.074581Z"
    }
   },
   "id": "7804b3a4c7e37a98"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Why do you need my order ID again? Can't you just look it up with my name or something? Fine, it's 12345. Get it done already!\n"
     ]
    }
   ],
   "source": [
    "result = sender_agent.invoke({\"input\": prompt, \"chat_history\": get_history_first(), \"civil\": 0})\n",
    "response = result\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:45:10.845908Z",
     "start_time": "2024-07-17T18:45:05.664414Z"
    }
   },
   "id": "fce98ceca1bbc999"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T20:04:00.287086Z",
     "start_time": "2024-07-09T20:04:00.253930Z"
    }
   },
   "id": "7162a3eadbdba1a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE)** : \"Are you serious? You should have all my information lready. It's 12345678. Do your job and fix this mess.\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12abedd4760124c8"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "historic_context = sender_agent.get_historical_context_chain().invoke({'question':prompt, \"chat_history\": get_history_first()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:11.735398Z",
     "start_time": "2024-07-09T01:33:10.506835Z"
    }
   },
   "id": "54d4c9008bf4f2ce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context**: 'Could you please provide your order ID for the refund request regarding your canceled flight?'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a376c78d2a324eca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Historic Context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec2da080027958f0"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "historic_context = info_agent.get_historical_info_context_chain().invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:16.258862Z",
     "start_time": "2024-07-09T01:33:15.449570Z"
    }
   },
   "id": "2f83b789262d4dfc"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'My order ID is 123456789. Please process my refund immediately.'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historic_context"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:33:16.259957Z",
     "start_time": "2024-07-09T01:33:16.204511Z"
    }
   },
   "id": "4d61e47700a3991d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Historic Context:**\n",
    "'My order ID is 12345678. Please resolve this issue promptly.'\n",
    "\n",
    "Output does not always reflect historic context, but rather only the most recent information provided by the customer. The invocation used here already leverages GPT-4o. Therefore, we need to adjust the prompts to reflect the actual context.\n",
    "Another problem is that the support panes need historical summaries, not just rephrases. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d791ea888bd45e2d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "client_completion = lcai.AzureOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-05-01\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"PROPILOT\",\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "def get_historical_context_chain():\n",
    "    contextualize_q_system_prompt = \"\"\"\n",
    "    Your role is to ensure that {message} can be understood without the chat history.\\\n",
    "    \n",
    "    The chat history contains an online conversation between a customer and a support representative.\\\n",
    "    The {message} is {sender}'s latest response in the chat.\\\n",
    "    \n",
    "    Summarize the chat history in a way that provides context for the {message}.\\\n",
    "    \"\"\"\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{sender}:{message}\"),\n",
    "        ]\n",
    "    )\n",
    "    contextualize_q_chain = contextualize_q_prompt | llminfo | StrOutputParser()\n",
    "    return contextualize_q_chain\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:46:42.926748Z",
     "start_time": "2024-07-17T18:46:42.879345Z"
    }
   },
   "id": "da28efd2e9853e15"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the conversation, a customer expressed frustration to a support representative about attempting to obtain a refund for a canceled flight for over a month. Despite being assured by the company on multiple occasions that the refund would be processed soon, the customer has yet to receive it. The representative apologized for the customer's bad experience and requested the order ID to further assist with the issue.\n"
     ]
    }
   ],
   "source": [
    "historic_context_chat = get_historical_context_chain().invoke({'sender':\"representative\",'message':prompt, \"chat_history\": get_history_first()})\n",
    "print(historic_context_chat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:08.564555Z",
     "start_time": "2024-07-09T01:34:06.087565Z"
    }
   },
   "id": "9f03edd4dcfa4e4a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation involves a customer expressing frustration over a delayed refund for a canceled flight with American Airlines. The customer has been attempting to resolve this issue for over a month, repeatedly being assured that the refund would be processed soon, yet has not received it. Upon request from the support representative for further details to assist with the matter, the customer provides their order ID, 123456789, and urges immediate action.\n"
     ]
    }
   ],
   "source": [
    "historic_context_info = get_historical_context_chain().invoke({'sender':\"client\",'message':response, \"chat_history\": get_history_second()})\n",
    "print(historic_context_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:34:21.465570Z",
     "start_time": "2024-07-09T01:34:17.003769Z"
    }
   },
   "id": "e180e424e42f1912"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Info Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f63e0622efc2074"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Confirm refund policy details.', 'Check the status of the refund process.', 'Apologize and assure resolution.']\n"
     ]
    }
   ],
   "source": [
    "info_agent = mAgentInfo()\n",
    "\n",
    "response_cw_info = info_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_cw_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:35:50.236487Z",
     "start_time": "2024-07-09T01:35:47.881477Z"
    }
   },
   "id": "bd6439efe1a973a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "['Apologize for the inconvenience caused.',\n",
    " 'Confirm receipt of the order ID provided.',\n",
    " 'Assure investigation and resolution.']\n",
    " \n",
    "The response above is using the old historical context approach and GPT-4. Some of the cues are more about ettiquette and less about the information elements. Sometimes the cues are full responses and not hints."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31bb7cbb0418f4b3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def extract_cues(chain_output):\n",
    "    cues_text = chain_output.content\n",
    "    # Assuming each cue is separated by a newline in the chain_output.\n",
    "    cues = cues_text.split('\\n')\n",
    "    # Filter out any empty strings or whitespace-only strings\n",
    "    cues = [cue.strip() for cue in cues if cue.strip()]\n",
    "    # Return the first 2 - 3 cues\n",
    "    processed_cues = [re.sub(r'^\\d+\\.\\s*', '', cue) for cue in cues]\n",
    "\n",
    "    return processed_cues\n",
    "\n",
    "def agent_coworker_info():\n",
    "    prompt = \"\"\"Your role is to help a service representative write a response to a customer they are chatting with online. \\\n",
    "\n",
    "            The representative needs to address the customer's complaint without escalating the issue to a supervisor.\\\n",
    "            The representatives response should have ONE of the following goals:\n",
    "            1) Inquire more details about the problem. OR \\\n",
    "            2) Request the customer to troubleshoot. OR \\\n",
    "            3) Provide a solution to resolve the customer's need. \\\n",
    "            \n",
    "            Given the chat history,\n",
    "            provide 3 hints to help the representative's response.\\\n",
    "            \n",
    "            Each hint should be a short phrase in a new line.\\\n",
    "            Do NOT number the cues.\\\n",
    "            Do NOT provide the representative with a full response,\\\n",
    "            ONLY provide hints to guide the representative's response.\\\n",
    "            \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "             | template\n",
    "             | llminfo\n",
    "             )\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:46:48.694556Z",
     "start_time": "2024-07-17T18:46:48.676913Z"
    }
   },
   "id": "a08d2e6de8d19945"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Empathize with the customer's frustration\", 'Confirm receipt of the order ID', 'Assure action will be taken promptly']\n"
     ]
    }
   ],
   "source": [
    "response_support_info = agent_coworker_info().invoke({'domain': \"airlines\",'message':response, \"chat_history\": get_history_second(), \"sender\": \"client\"})\n",
    "print(response_support_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:04:52.949894Z",
     "start_time": "2024-07-09T02:04:48.207918Z"
    }
   },
   "id": "e547fb34ab39baa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "['Explain the necessity for the order ID to locate the specific booking.', 'Reassure the customer that this will expedite the process.', 'Apologize for the inconvenience and frustration caused.']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1500610e9315394f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c35a45817a7961d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trouble Support Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15b299f014a7a960"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "response_cw_trouble = trouble_agent.invoke({'domain': \"airlines\",'complaint':response, \"chat_history\": get_history_second()})\n",
    "\n",
    "print(response_cw_trouble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T01:37:27.314280Z",
     "start_time": "2024-07-09T01:37:26.312635Z"
    }
   },
   "id": "658ed7a9933157c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:** \n",
    "Step 1: Verify customer's order ID.\n",
    "Step 2: Review similar cases for resolution.\n",
    "Step 3: Assess current situation in depth.\n",
    "Step 4: Explain airline's policy on refunds.\n",
    "Step 5: Offer alternative solution if refund is not possible.\n",
    "Step 6: Apologize for inconvenience caused.\n",
    "Step 7: Ensure resolution is satisfactory to customer.\n",
    " \n",
    "The traditional method does not look at the history correctly. This is why the response does not filter and adjust according to the context. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a68e8e906b67004"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "def agent_coworker_trouble():\n",
    "    client = mLangChain()\n",
    "    prompt = \"\"\"Your role is to guide a service representative to  resolve the complaint of a customer, to whom they are chatting with online. \\\n",
    "\n",
    "            The representative needs to address the customer's complaint without escalating the issue to a supervisor.\\\n",
    "            \n",
    "            Review the chat history to understand the steps the representative has taken in response to the complaint. \\\n",
    "            \n",
    "            Apart from apologies and assurances,\\\n",
    "            list 3-7 items of procedure the representative needs to consider to best service the complaint.\\\n",
    "            \n",
    "            ONLY list actionable and specific items.\\\n",
    "            AVOID vague or general suggestions.\\\n",
    "            DO NOT list action items that the representative has already taken.\\\n",
    "            Every item should be less than 10 words.\\\n",
    "                            \n",
    "            Every item should be in a newline.\\\n",
    "                    \n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{domain}: {message}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = (RunnablePassthrough.assign(\n",
    "        context=get_historical_context_chain()\n",
    "    )\n",
    "            | template\n",
    "            | llminfo\n",
    "            )\n",
    "\n",
    "    chain = chain | extract_cues\n",
    "    \n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T19:46:53.359271Z",
     "start_time": "2024-07-11T19:46:53.339270Z"
    }
   },
   "id": "74ef8167c2c9efac"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Verify the order ID in the system.', 'Check the status of the refund request.', 'Confirm the refund processing timeline.', 'Provide a specific date for refund completion.', 'Offer alternative compensation if refund delay persists.', 'Send a confirmation email with refund details.', 'Follow up with the customer after refund completion.']\n"
     ]
    }
   ],
   "source": [
    "response_cw_trouble = agent_coworker_trouble().invoke({'domain': \"airlines\",'message':response, \"sender\": \"client\", \"chat_history\": get_history_second()})\n",
    "\n",
    "print(response_cw_trouble)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T19:46:57.154782Z",
     "start_time": "2024-07-11T19:46:54.553696Z"
    }
   },
   "id": "aef83689ad74ef41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reframing Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d7c695d678aa7d"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: This customer seems very angry and I can understand their frustration. I need to handle this situation carefully and try to find a solution for them as soon as possible.\n",
      "Reframe: I can empathize with the customer's frustration and understand their urgency. It's important for me to focus on finding a solution for their issue and communicate clearly and effectively to ensure a positive outcome.\n"
     ]
    }
   ],
   "source": [
    "emo_agent = mAgentER()\n",
    "response_cw_emo = emo_agent.invoke({'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_cw_emo['thought'])\n",
    "print(response_cw_emo['reframe'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T13:29:17.730111Z",
     "start_time": "2024-07-09T13:29:15.518111Z"
    }
   },
   "id": "a6edc1cf4e3a3225"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_situation_old():\n",
    "    client = mLangChain()\n",
    "\n",
    "    prompt = \"\"\"The chat history describes a representative chatting online with a complaining customer. \\\n",
    "    The latest input is the last message from the customer \\\n",
    "    which can be understood without the chat history.\\\n",
    "    Describe the situation with respect to the customer's behavior towards the representative.\\\n",
    "    Include the specifics of the complaint while describing the situation.\\\n",
    "                    \n",
    "    Do NOT respond to the input, just summarize the situation.\\\n",
    "    Do NOT speculate.\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client.client_completion\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:22.199591Z",
     "start_time": "2024-07-17T18:47:22.168865Z"
    }
   },
   "id": "793874076c825c2c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The customer is frustrated and impatient with the representative's lack of progress in processing their refund for a canceled flight. They are also annoyed that the representative is asking for their order ID again and just wants the issue to be resolved.\n"
     ]
    }
   ],
   "source": [
    "response_situation = agent_coworker_emo_situation_old().invoke({'complaint':response, \"chat_history\": get_history_second()})\n",
    "print(response_situation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:23.754934Z",
     "start_time": "2024-07-17T18:47:22.967257Z"
    }
   },
   "id": "252d455fe99ffe92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response:**\n",
    "\"The customer is angry and frustrated with the representative and the company's lack of action in processing their refund. They have been trying to resolve the issue for over a month and have not received a satisfactory response. Their specific complaint is regarding the delay in receiving a refund for a canceled flight and they find this unacceptable. They are demanding immediate action to be taken.\"\n",
    "\n",
    "One of the problems with the existing prompt design is that the \"situation\" does not capture the interpersonal conflict between the customer and the representative. This is a key aspect of the conversation that should be addressed in the prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48dceb193de34e2a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_situation():\n",
    "    prompt = \"\"\"The chat history describes a representative chatting online with a complaining customer.\\\n",
    "    The latest input is the last message from the customer.\\\n",
    "    \n",
    "    Summarize the situation in concise paragraph that uses the following template:\\\n",
    "    \n",
    "    The customer is  <context of complaint>.\"\\\n",
    "    The customer is feeling <emotional state> because of the complaint.\"\\\n",
    "    The customer's behavior towards the representative is <negative behavior>, as observed by statements such as <evidence>.\"\\\n",
    "    These behaviors make the representative look <negative perception>.\"\\\n",
    "\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{sender} : {complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:26.313915Z",
     "start_time": "2024-07-17T18:47:26.288864Z"
    }
   },
   "id": "860d9202d0c81b24"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer is frustrated with the delay in receiving a refund for a canceled flight. The customer is feeling exasperated because of the prolonged wait and lack of resolution. The customer's behavior towards the representative is impatient and demanding, as observed by statements such as \"Why do you need my order ID again? Can't you just look it up with my name or something? Fine, it's 12345. Get it done already!\" These behaviors make the representative look inefficient and unhelpful.\n"
     ]
    }
   ],
   "source": [
    "response_situation = agent_coworker_emo_situation().invoke({'complaint':response, \"sender\":\"customer\", \"chat_history\": get_history_second()})\n",
    "print(response_situation.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:28.937548Z",
     "start_time": "2024-07-17T18:47:26.935545Z"
    }
   },
   "id": "838948b1fb49607"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "The customer is frustrated with the delay in receiving a refund for a canceled flight. The customer is feeling exasperated because of the prolonged and unresolved issue. The customer's behavior towards the representative is impatient and demanding, as observed by statements such as \"Why do you need my order ID again? I've given it a million times already!\" and \"Now get on with it and sort this mess out.\" These behaviors make the representative look inefficient and unhelpful."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e2d8ffeabd504d1"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def agent_coworker_emo_thought_old():\n",
    "    client = mLangChain()\n",
    "\n",
    "    prompt = \"\"\"You are roleplaying as the representative talking to a complaining customer.\\\n",
    "        Refer to the chat history between you and the customer and the latest {complaint} from the customer.\\\n",
    "        What is the representative thinking about the situation?\\\n",
    "        Be concise. Only 2 sentences.\\\n",
    "        \n",
    "        Situation: An mturk requester rejected my task and I wasn't sure why because I work very hard on my tasks. Being new it affected my approval rating more negatively.\\\n",
    "        Thought: I'm not smart enough to succeed at mturk\\\n",
    "        \n",
    "        Situation: I asked my daughter a question, and she responded in a snotty way.\\\n",
    "        Thought: She doesn't love me like she used to.\\\n",
    "        \n",
    "        Situation: I got upset at my boss for not putting me in a temporary promotion to act as supervisor of our team.\\\n",
    "        Thought: I wasn't valued as much as the other person.\\\n",
    "        \n",
    "        Situation: I had been working on a project at work for a very long time, but a higher up manager contacted my boss and asked about it, insinuating I wasn't delivering it fast enough.\\\n",
    "        Thought: I'm working on this as fast as I possibly can.\\\n",
    "        \n",
    "        Situation: I tried on my wedding dress in front of my family. My mother was excited and told me I was beautiful, but other members of my family made comments about my weight. I was told to not eat and exercise so I could be beautiful.\\\n",
    "        Thought: I'm a fat ugly troll.\\\n",
    "        \n",
    "        Situation: I was reprimanded at work for standing up to a coworker who was bullying another co-worker.\\\n",
    "        Thought: It was unfair that I was the one to get in trouble for defending a weaker person.\\\n",
    "        \n",
    "        Situation: {situation}\\\n",
    "        Thought:\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{situation}: {complaint}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client.client_completion\n",
    "\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:30.435258Z",
     "start_time": "2024-07-17T18:47:30.418153Z"
    }
   },
   "id": "da61cc1bbb3d4718"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thought: The customer seems agitated and impatient, making it difficult for me to assist them.\n"
     ]
    }
   ],
   "source": [
    "thought = agent_coworker_emo_thought_old().invoke({'complaint':response, 'situation':response_situation.content, 'chat_history':get_history_second()})\n",
    "\n",
    "print(thought)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:32.327603Z",
     "start_time": "2024-07-17T18:47:31.773723Z"
    }
   },
   "id": "22ea0f69ef5a0eb1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response(s):**\n",
    "Thought: The customer seems to be feeling extremely frustrated and is taking out their anger on the representative, who is trying their best to remain calm and resolve the issue.\n",
    "\n",
    "AI: I understand your frustration, and I apologize for the inconvenience. Could you please provide your order ID again so I can ensure that the refund is processed as quickly as possible? Thank you for your patience and understanding.\n",
    "\n",
    "The problem with this approach is that it is still a summary or sometimes a response. It does not capture the ego-threat or the emotional state of the customer. The prompt should be updated to reflect this."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95e2a1edaf4c4f9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_thought():\n",
    "\n",
    "    prompt = \"\"\"\n",
    "        Your role is to derive what negative thought a representative might have when faced with the given {situation}.\\\n",
    "        \n",
    "        Here are examples of negative thoughts given challenging situations:\\\n",
    "        \n",
    "        Situation: I recently discovered a music artist that I very much enjoy. When I showed it to a close friend they had a very negative reaction and asked me how I could enjoy this type of music. I ended up getting quite angry with them and told them they had bad taste in music..\\\n",
    "        Thought: I felt that my personal self was under attack - and I needed to retaliate by denying their attack.\\\n",
    "        \n",
    "        Situation: I was at work and sent info for an ad to our local newspaper. They called me later and said my boss had over-ridden everything and sent them new info.\\\n",
    "        Thought: He shouldn't assign me a task if he doesn't trust my work.\\\n",
    "        \n",
    "        Situation: I was reprimanded at work for standing up to a coworker who was bullying another co-worker.\\\n",
    "        Thought: It was unfair that I was the one to get in trouble for defending a weaker person.\\\n",
    "        \n",
    "        Situation: I was talking to a friend who got me angry.\\\n",
    "        Thought: He's insulting me.\\\n",
    "        \n",
    "        Situation: My next door neighbors filed a complaint against us last week blaming our dogs for excessive barking.\\\n",
    "        Thought: They are so wrong and I'm so pissed but I know I can't prove it and they will probably win because they won't ever admit it and I have to do something right NOW! or I might lose my dogs.\\\n",
    "        \n",
    "        Situation: Time is running short on the workday, my boss asks me if I can finish a task that will require me to stay for a few extra hours.\\\n",
    "        Thought: Why would you wait until the last minute to ask me this.\\\n",
    "        \n",
    "        Situation: {situation}\\\n",
    "        Thought:\\\n",
    "        \n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{situation}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo | StrOutputParser()\n",
    "    return chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:36.281252Z",
     "start_time": "2024-07-17T18:47:36.276407Z"
    }
   },
   "id": "110658097eaf649a"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The customer thinks I'm incompetent and doesn't trust that I can resolve their issue.\n"
     ]
    }
   ],
   "source": [
    "thought = agent_coworker_emo_thought().invoke({'situation':response_situation.content, 'chat_history':get_history_second()})\n",
    "\n",
    "print(thought)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:39.072108Z",
     "start_time": "2024-07-17T18:47:37.478300Z"
    }
   },
   "id": "4d2e29ba361e1df5"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It might seem like the customer doubts your abilities and doesn't believe you can fix their problem.\n"
     ]
    }
   ],
   "source": [
    "def rephrase():\n",
    "    prompt = \"\"\"\n",
    "                Person A might be thinking: {thought}\\\n",
    "                \n",
    "                Acknowledge the thought, as if you are speaking to Person A.\\\n",
    "                \n",
    "                Begin your response with phrases such as:\\\n",
    "                - \"You might be thinking...\"\\\n",
    "                - \"It might seem like...\"\\\n",
    "                - \"It could be that you are feeling...\"\\\n",
    "                \n",
    "                Your rephrase should be concise.\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"{thought}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo | StrOutputParser()\n",
    "    return chain\n",
    "\n",
    "rephrase_thought = rephrase().invoke({'thought':thought})\n",
    "print(rephrase_thought)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:40.419324Z",
     "start_time": "2024-07-17T18:47:39.811649Z"
    }
   },
   "id": "6c0e85136836e9bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "It might seem like, despite your best efforts, the customer perceives you as incompetent and unhelpful, which is frustrating, especially when the issue is beyond your control."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4232cb9e2db5604"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:43.948823Z",
     "start_time": "2024-07-17T18:47:43.929893Z"
    }
   },
   "id": "d6e0766b86d894fb"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def agent_coworker_emo_reframe_old():\n",
    "    client = mLangChain()\n",
    "\n",
    "    prompt = \"\"\"You are a representative chatting online with a complaining customer.\\\n",
    "                            \n",
    "                Reframe your thoughts in the given situation.\n",
    "                \n",
    "                Situation: An mturk requester rejected my task and I wasn't sure why because I work very hard on my tasks. Being new it affected my approval rating more negatively.\\\n",
    "                Thought: I'm not smart enough to succeed at mturk\\\n",
    "                Reframe: It seems like there was some miscommunication. It doesn't mean that I do not have the skills to do well with mturk. I should reach out to see if I can get more clarity on why my task was rejected.\\\n",
    "                \n",
    "                Situation: I asked my daughter a question, and she responded in a snotty way.\\\n",
    "                Thought: She doesn't love me like she used to.\\\n",
    "                Reframe: Kids say snappy things to their parents all the time. It doesn't mean I'm a bad parent or that she doesn't love me.\\\n",
    "                \n",
    "                Situation: I got upset at my boss for not putting me in a temporary promotion to act as supervisor of our team.\\\n",
    "                Thought: I wasn't valued as much as the other person.\\\n",
    "                Reframe: I should ask my boss why I was not selected for the promotion. Maybe the reason will be something other than my work ethic. Maybe my boss will reassure that I am still valuable to the company.\\\n",
    "                \n",
    "                Situation: I had been working on a project at work for a very long time, but a higher up manager contacted my boss and asked about it, insinuating I wasn't delivering it fast enough.\\\n",
    "                Thought: I'm working on this as fast as I possibly can.\\\n",
    "                Reframe: I am stressed by trying to compare how fast I am working on this to how fast I think other people complete their assignments. I know I am being efficient with my time and producing good work. I need to focus on that to get this task done.\\\n",
    "                \n",
    "                Situation: I tried on my wedding dress in front of my family. My mother was excited and told me I was beautiful, but other members of my family made comments about my weight. I was told to not eat and exercise so I could be beautiful.\\\n",
    "                Thought: I'm a fat ugly troll.\\\n",
    "                Reframe: The commend about my weight hurt and have me feeling self conscious. I'm glad my mother thinks I'm beautiful and know that my weight does not dictate my worth.\\\n",
    "                \n",
    "                Situation: I was reprimanded at work for standing up to a coworker who was bullying another co-worker.\\\n",
    "                Thought: It was unfair that I was the one to get in trouble for defending a weaker person.\\\n",
    "                Reframe: I can own some responsibility for this conflict that occurred at work.\\\n",
    "                \n",
    "                Situation: {situation}\\\n",
    "                Thought: {thought}\\\n",
    "                Reframe:\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"{situation}: {thought}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | client.client_completion\n",
    "\n",
    "    return chain\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:47:44.960613Z",
     "start_time": "2024-07-17T18:47:44.943492Z"
    }
   },
   "id": "b6fce39956623736"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reframe: The customer is understandably frustrated and wants a quick resolution. I will do my best to provide efficient and effective assistance, even if it means asking for necessary information like the order ID. I am confident in my abilities to resolve this issue for the customer.\n"
     ]
    }
   ],
   "source": [
    "reframe = agent_coworker_emo_reframe_old().invoke({'thought':thought, 'situation':response_situation.content})\n",
    "\n",
    "print(reframe)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:48:05.772166Z",
     "start_time": "2024-07-17T18:48:04.747363Z"
    }
   },
   "id": "697690e71a5bff1e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sample Response:\n",
    "Reframe: I can empathize with the customer's frustration and understand their urgency. It's important for me to focus on finding a solution for their issue and communicate clearly and effectively to ensure a positive outcome.\n",
    "\n",
    "Reframe (After updating Situation/Thought): The customer may be feeling extremely frustrated and is taking it out on me. It's not a reflection of my competence or helpfulness. I will try my best to remain calm and find a solution to their issue."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39c3083de3c1baaa"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reframe: The customer is understandably frustrated due to the delay in receiving their refund and is expressing their impatience. Their frustration is directed at the situation, not necessarily at me personally. I can empathize with their feelings and work efficiently to resolve their issue, showing them that I am here to help and capable of providing a solution.\n"
     ]
    }
   ],
   "source": [
    "def agent_coworker_emo_reframe():\n",
    "    prompt = \"\"\"You are a representative chatting online with a complaining customer.\\\n",
    "                            \n",
    "                Reframe your thoughts in the given situation.\n",
    "                    \n",
    "                \n",
    "                Situation: I recently discovered a music artist that I very much enjoy. When I showed it to a close friend they had a very negative reaction and asked me how I could enjoy this type of music. I ended up getting quite angry with them and told them they had bad taste in music..\\\n",
    "                Thought: I felt that my personal self was under attack - and I needed to retaliate by denying their attack.\\\n",
    "                Reframe: I was offended by their comment because I like this artist so much. I let my anger get to me, and I said something mean in return. It is okay if we have different music tastes. I can ask him to be nicer to me next time.\\\n",
    "                \n",
    "                \n",
    "                Situation: I was at work and sent info for an ad to our local newspaper. They called me later and said my boss had over-ridden everything and sent them new info.\\\n",
    "                Thought: He shouldn't assign me a task if he doesn't trust my work.\\\n",
    "                Reframe: My boss wanted to provide different information, I did not know that beforehand. This is not a reflection of my work.\\\n",
    "                \n",
    "                \n",
    "                Situation: I was talking to a friend who got me angry.\\\n",
    "                Thought: He's insulting me.\\\n",
    "                Reframe: I should have a conversation with my friend to clarify what is going on if I am having such a strong reaction to what they said. If this is the first time this has happened, I will assume that they were not intentionally insulting me.\\\n",
    "                \n",
    "                \n",
    "                    \n",
    "                Situation: {situation}\\\n",
    "                Thought: {thought}\\\n",
    "                Reframe:\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"{situation}: {thought}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo | StrOutputParser()\n",
    "\n",
    "    return chain\n",
    "\n",
    "\n",
    "reframe = agent_coworker_emo_reframe().invoke({'thought': thought, 'situation': response_situation.content})\n",
    "\n",
    "print(reframe)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:48:18.008329Z",
     "start_time": "2024-07-17T18:48:14.416204Z"
    }
   },
   "id": "4b6809098b151eaa"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You understand that the customer is frustrated due to the delay in receiving their refund and that their frustration is directed at the situation, not at you personally. You can empathize with their feelings and work efficiently to resolve their issue, showing them that you are here to help and capable of providing a solution.\n"
     ]
    }
   ],
   "source": [
    "def rephrase_rf():\n",
    "    prompt = \"\"\"\n",
    "                The representative needs to be thinking: {thought}\\\n",
    "                \n",
    "                Rephrase the thought as if you are convincing the representative to think that way.\\\n",
    "                \n",
    "                The rephrase should be addressed back to the person who has the thought,\\\n",
    "                who should be referred to as \"you\".\\\n",
    "                Do NOT add information to the thought,\\\n",
    "                ONLY rephrase it.\\\n",
    "                \n",
    "                The rephrase should be concise and only 2-3 sentences.\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{thought}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo | StrOutputParser()\n",
    "    return chain\n",
    "\n",
    "rephrase_reframe = rephrase_rf().invoke({'thought':reframe, 'chat_history':get_history_second()})\n",
    "print(rephrase_reframe)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-17T18:49:09.670858Z",
     "start_time": "2024-07-17T18:49:08.499638Z"
    }
   },
   "id": "57607fd385925d47"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sample Response (POST-UPDATE):**\n",
    "Remember, the customer's frustration is about the delay, not you personally. Stay calm and professional, empathize with their situation, and focus on resolving their issue efficiently. Clear and consistent communication will help ease their concerns and show your commitment to helping them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62ba55dc087df744"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Similarity Test\n",
    "\n",
    "Can we use the similarity test to compare the old and new responses provided by the LLM?\n",
    "If the thought is not particularly different, then the reframe should does not need to be rendered."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ece6a0627583d74a"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different.\n",
      "\n",
      "1. The first statement focuses on the customer's perception of your efforts as inadequate and views you as incompetent. It emphasizes the customer's perspective and how they might see your actions.\n",
      "2. The second statement addresses your feelings of incompetence and being overwhelmed due to your efforts never seeming sufficient. It emphasizes your internal experience and emotional response to the situation.\n",
      "\n",
      "Both statements acknowledge the customer's frustration due to discomfort, but they differ in their focus on either the customer's perception or your personal feelings.\n"
     ]
    }
   ],
   "source": [
    "test_thoughts = ['''\n",
    "It might seem like no matter what you do, the customer perceives your efforts as inadequate and views you as incompetent.\n",
    "You understand that the customer is frustrated because they are uncomfortable and unable to sleep due to the air conditioning issue. Their demanding behavior reflects their discomfort, not your competence. You can empathize with their situation and assure them that you are doing everything to resolve the issue promptly.''',\n",
    "'''\n",
    "It might seem like no matter how hard you try, your efforts are never sufficient, and this could be making you feel incompetent and overwhelmed in your job.\n",
    "The customer is understandably frustrated because they are uncomfortable and unable to sleep. Their impatience is due to their discomfort, not your abilities. Stay calm and professional, and focus on resolving the issue quickly to improve their experience.\n",
    "''',\n",
    "'''\n",
    "You might be thinking that it's unfair for the customer to blame you for issues you didn't cause.\n",
    "You understand that the customer is frustrated and needs their concerns addressed. While you're not personally responsible for the issues, you can empathize with their situation and work towards finding a solution to improve their experience.\n",
    "''',\n",
    "'''\n",
    "It might seem like this customer is being unreasonable and venting their frustration on you, which feels unfair since you're just trying to assist them.\n",
    "You can see that the customer is frustrated and uncomfortable with their room, which is why they're expressing their concerns strongly. Stay calm and empathetic, and focus on resolving their issues quickly and efficiently. By addressing their concerns, you'll improve their experience and show that you value their feedback.\n",
    "'''\n",
    "]\n",
    "\n",
    "def similarity_check():\n",
    "    prompt = \"\"\"\n",
    "                Compare the statements in the given thoughts.\\\n",
    "                \n",
    "                Respond if these are similar or different: \"Similar/Different\"\\\n",
    "                \n",
    "                If different, describe the differences.\\\n",
    "                \"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", prompt),\n",
    "            (\"user\", \"{thought1} vs {thought2}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | llmemo | StrOutputParser()\n",
    "    return chain\n",
    "\n",
    "similarity = similarity_check().invoke({'thought1':test_thoughts[0], 'thought2':test_thoughts[1]})\n",
    "print(similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T20:26:12.761603Z",
     "start_time": "2024-07-11T20:26:10.080166Z"
    }
   },
   "id": "59704b3e1462eea8"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different.\n",
      "\n",
      "1. The first statement emphasizes understanding the customer's frustration and empathizing with their situation, even though you are not personally responsible for the issues. It focuses on working towards a solution to improve the customer's experience.\n",
      "\n",
      "2. The second statement suggests that the customer might seem unreasonable and is venting their frustration on you, which feels unfair. However, it also emphasizes staying calm and empathetic, and focuses on resolving the customer's issues quickly and efficiently to improve their experience and show that their feedback is valued.\n",
      "\n",
      "The main differences are:\n",
      "- The first statement does not mention the customer being unreasonable or venting frustration on you, while the second statement does.\n",
      "- The first statement focuses more on understanding and empathizing with the customer's situation, while the second statement acknowledges the feeling of unfairness but still emphasizes the importance of resolving the issues and valuing the customer's feedback.\n"
     ]
    }
   ],
   "source": [
    "similarity = similarity_check().invoke({'thought1':test_thoughts[2], 'thought2':test_thoughts[3]})\n",
    "print(similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-11T20:26:30.980805Z",
     "start_time": "2024-07-11T20:26:23.845935Z"
    }
   },
   "id": "28ab74759b2b957"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "70a992b3a75d1a29"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
